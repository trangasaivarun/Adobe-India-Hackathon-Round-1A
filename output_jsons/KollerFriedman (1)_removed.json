{
  "title": "Probabilistic Graphical Models",
  "outline": [
    {
      "level": "H4",
      "text": "Probabilistic Graphical Models",
      "page": 2
    },
    {
      "level": "H4",
      "text": "Adaptive Computation and Machine Learning",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Thomas Dietterich, Editor",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Christopher Bishop, David Heckerman, Michael Jordan, and Michael Kearns, Associate Editors",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Bioinformatics: The Machine Learning Approach, Pierre Baldi and Søren Brunak",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Reinforcement Learning: An Introduction, Richard S. Sutton and Andrew G. Barto",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Graphical Models for Machine Learning and Digital Communication, Brendan J. Frey",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Learning in Graphical Models, Michael I. Jordan",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Causation, Prediction, and Search, 2nd ed., Peter Spirtes, Clark Glymour, and Richard Scheines",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Principles of Data Mining, David Hand, Heikki Mannila, and Padhraic Smyth",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Bioinformatics: The Machine Learning Approach, 2nd ed., Pierre Baldi and Søren Brunak",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Learning Kernel Classiﬁers: Theory and Algorithms, Ralf Herbrich",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond, Bern-",
      "page": 3
    },
    {
      "level": "H5",
      "text": "hard Schölkopf and Alexander J. Smola",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Introduction to Machine Learning, Ethem Alpaydin",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Gaussian Processes for Machine Learning, Carl Edward Rasmussen and Christopher K. I. Williams",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Semi-Supervised Learning, Olivier Chapelle, Bernhard Schölkopf, and Alexander Zien, eds.",
      "page": 3
    },
    {
      "level": "H5",
      "text": "The Minimum Description Length Principle, Peter D. Grünwald",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Introduction to Statistical Relational Learning, Lise Getoor and Ben Taskar, eds.",
      "page": 3
    },
    {
      "level": "H5",
      "text": "Probabilistic Graphical Models: Principles and Techniques, Daphne Koller and Nir Friedman",
      "page": 3
    },
    {
      "level": "H2",
      "text": "Principles and Techniques",
      "page": 4
    },
    {
      "level": "H2",
      "text": "Daphne Koller",
      "page": 4
    },
    {
      "level": "H2",
      "text": "Nir Friedman",
      "page": 4
    },
    {
      "level": "H5",
      "text": "The MIT Press",
      "page": 4
    },
    {
      "level": "H5",
      "text": "Cambridge, Massachusetts",
      "page": 4
    },
    {
      "level": "H5",
      "text": "London, England",
      "page": 4
    },
    {
      "level": "H5",
      "text": "©2009 Massachusetts Institute of Technology",
      "page": 5
    },
    {
      "level": "H5",
      "text": "All rights reserved. No part of this book may be reproduced in any form by any electronic",
      "page": 5
    },
    {
      "level": "H5",
      "text": "or mechanical means (including photocopying, recording, or information storage and retrieval)",
      "page": 5
    },
    {
      "level": "H5",
      "text": "without permission in writing from the publisher.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "For information about special quantity discounts, please email special_sales@mitpress.mit.edu",
      "page": 5
    },
    {
      "level": "H5",
      "text": "This book was set by the authors in LATEX2￿.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "Printed and bound in the United States of America.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "Library of Congress Cataloging-in-Publication Data",
      "page": 5
    },
    {
      "level": "H5",
      "text": "Koller, Daphne.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "Probabilistic Graphical Models: Principles and Techniques / Daphne Koller and Nir Friedman.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "p. cm. – (Adaptive computation and machine learning)",
      "page": 5
    },
    {
      "level": "H5",
      "text": "Includes bibliographical references and index.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "ISBN 978-0-262-01319-2 (hardcover : alk. paper)",
      "page": 5
    },
    {
      "level": "H5",
      "text": "1. Graphical modeling (Statistics) 2. Bayesian statistical decision theory—Graphic methods.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "Koller, Daphne. II. Friedman, Nir.",
      "page": 5
    },
    {
      "level": "H5",
      "text": "QA279.5.K65 2010",
      "page": 5
    },
    {
      "level": "H5",
      "text": "519.5’420285–dc22",
      "page": 5
    },
    {
      "level": "H5",
      "text": "2009008615",
      "page": 5
    },
    {
      "level": "H4",
      "text": "To our families",
      "page": 6
    },
    {
      "level": "H5",
      "text": "my parents Dov and Ditza",
      "page": 6
    },
    {
      "level": "H5",
      "text": "my husband Dan",
      "page": 6
    },
    {
      "level": "H5",
      "text": "my daughters Natalie and Maya",
      "page": 6
    },
    {
      "level": "H5",
      "text": "D.K.",
      "page": 6
    },
    {
      "level": "H5",
      "text": "my parents Noga and Gad",
      "page": 6
    },
    {
      "level": "H5",
      "text": "my wife Yael",
      "page": 6
    },
    {
      "level": "H5",
      "text": "my children Roy and Lior",
      "page": 6
    },
    {
      "level": "H5",
      "text": "N.F.",
      "page": 6
    },
    {
      "level": "H5",
      "text": "As far as the laws of mathematics refer to reality, they are not certain, as far as they are",
      "page": 8
    },
    {
      "level": "H5",
      "text": "certain, they do not refer to reality.",
      "page": 8
    },
    {
      "level": "H5",
      "text": "Albert Einstein, 1921",
      "page": 8
    },
    {
      "level": "H5",
      "text": "When we try to pick out anything by itself, we ﬁnd that it is bound fast by a thousand",
      "page": 8
    },
    {
      "level": "H5",
      "text": "invisible cords that cannot be broken, to everything in the universe.",
      "page": 8
    },
    {
      "level": "H5",
      "text": "John Muir, 1869",
      "page": 8
    },
    {
      "level": "H5",
      "text": "The actual science of logic is conversant at present only with things either certain, impossible,",
      "page": 8
    },
    {
      "level": "H5",
      "text": "or entirely doubtful . . . Therefore the true logic for this world is the calculus of probabilities,",
      "page": 8
    },
    {
      "level": "H5",
      "text": "which takes account of the magnitude of the probability which is, or ought to be, in a",
      "page": 8
    },
    {
      "level": "H5",
      "text": "reasonable man’s mind.",
      "page": 8
    },
    {
      "level": "H5",
      "text": "James Clerk Maxwell, 1850",
      "page": 8
    },
    {
      "level": "H5",
      "text": "The theory of probabilities is at bottom nothing but common sense reduced to calculus; it",
      "page": 8
    },
    {
      "level": "H5",
      "text": "enables us to appreciate with exactness that which accurate minds feel with a sort of instinct",
      "page": 8
    },
    {
      "level": "H5",
      "text": "for which ofttimes they are unable to account.",
      "page": 8
    },
    {
      "level": "H5",
      "text": "Pierre Simon Laplace, 1819",
      "page": 8
    },
    {
      "level": "H5",
      "text": "Misunderstanding of probability may be the greatest of all impediments to scientiﬁc literacy.",
      "page": 8
    },
    {
      "level": "H5",
      "text": "Stephen Jay Gould",
      "page": 8
    },
    {
      "level": "H2",
      "text": "Contents",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Acknowledgments",
      "page": 10
    },
    {
      "level": "H5",
      "text": "xxiii",
      "page": 10
    },
    {
      "level": "H5",
      "text": "List of Figures",
      "page": 10
    },
    {
      "level": "H5",
      "text": "xxv",
      "page": 10
    },
    {
      "level": "H5",
      "text": "List of Algorithms",
      "page": 10
    },
    {
      "level": "H5",
      "text": "xxxi",
      "page": 10
    },
    {
      "level": "H5",
      "text": "List of Boxes",
      "page": 10
    },
    {
      "level": "H5",
      "text": "xxxiii",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.1",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.2",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Probabilistic Graphical Models",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Representation, Inference, Learning",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Motivation",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Structured Probabilistic Models",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.2.1",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.2.2",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Overview and Roadmap",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.3.1",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.3.2",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.3.3",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Historical Notes",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Overview of Chapters",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Reader’s Guide",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Connection to Other Disciplines",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2 Foundations",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Probability Distributions",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Basic Concepts in Probability",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Random Variables and Joint Distributions",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Independence and Conditional Independence",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Querying a Distribution",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Continuous Spaces",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Expectation and Variance",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Probability Theory",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.1",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.2",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.3",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.4",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.5",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.6",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1.7",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Graphs",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.2.1",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.2.2",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.2.3",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Nodes and Edges",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Subgraphs",
      "page": 10
    },
    {
      "level": "H5",
      "text": "Paths and Trails",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.3",
      "page": 10
    },
    {
      "level": "H5",
      "text": "1.4",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.1",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.2",
      "page": 10
    },
    {
      "level": "H5",
      "text": "2.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "2.4",
      "page": 11
    },
    {
      "level": "H5",
      "text": "2.2.4",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Cycles and Loops",
      "page": 11
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 11
    },
    {
      "level": "H4",
      "text": "I Representation",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3 The Bayesian Network Representation",
      "page": 11
    },
    {
      "level": "H5",
      "text": "The Student Example Revisited",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Basic Independencies in Bayesian Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Graphs and Distributions",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Independent Random Variables",
      "page": 11
    },
    {
      "level": "H5",
      "text": "The Conditional Parameterization",
      "page": 11
    },
    {
      "level": "H5",
      "text": "The Naive Bayes Model",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Exploiting Independence Properties",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.1.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.1.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.1.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Bayesian Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.2.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.2.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.2.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Independencies in Graphs",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.3.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.3.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.3.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.3.4",
      "page": 11
    },
    {
      "level": "H5",
      "text": "From Distributions to Graphs",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.4.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.4.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.4.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Minimal I-Maps",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Perfect Maps",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Finding Perfect Maps (cid:63)",
      "page": 11
    },
    {
      "level": "H5",
      "text": "D-separation",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Soundness and Completeness",
      "page": 11
    },
    {
      "level": "H5",
      "text": "An Algorithm for d-Separation",
      "page": 11
    },
    {
      "level": "H5",
      "text": "I-Equivalence",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.4",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.5",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.6",
      "page": 11
    },
    {
      "level": "H5",
      "text": "3.7",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4 Undirected Graphical Models",
      "page": 11
    },
    {
      "level": "H5",
      "text": "103",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.4",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.5",
      "page": 11
    },
    {
      "level": "H5",
      "text": "110",
      "page": 11
    },
    {
      "level": "H5",
      "text": "103",
      "page": 11
    },
    {
      "level": "H5",
      "text": "106",
      "page": 11
    },
    {
      "level": "H5",
      "text": "106",
      "page": 11
    },
    {
      "level": "H5",
      "text": "The Misconception Example",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Parameterization",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Factors",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.2.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Gibbs Distributions and Markov Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.2.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.2.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Reduced Markov Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Markov Network Independencies",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.3.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.3.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.3.3",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Parameterization Revisited",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Finer-Grained Parameterization",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.4.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.4.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Overparameterization",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Bayesian Networks and Markov Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.5.1",
      "page": 11
    },
    {
      "level": "H5",
      "text": "4.5.2",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Basic Independencies",
      "page": 11
    },
    {
      "level": "H5",
      "text": "Independencies Revisited",
      "page": 11
    },
    {
      "level": "H5",
      "text": "From Distributions to Graphs",
      "page": 11
    },
    {
      "level": "H5",
      "text": "From Bayesian Networks to Markov Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "From Markov Networks to Bayesian Networks",
      "page": 11
    },
    {
      "level": "H5",
      "text": "120",
      "page": 11
    },
    {
      "level": "H5",
      "text": "128",
      "page": 11
    },
    {
      "level": "H5",
      "text": "123",
      "page": 11
    },
    {
      "level": "H5",
      "text": "122",
      "page": 11
    },
    {
      "level": "H5",
      "text": "134",
      "page": 11
    },
    {
      "level": "H5",
      "text": "114",
      "page": 11
    },
    {
      "level": "H5",
      "text": "114",
      "page": 11
    },
    {
      "level": "H5",
      "text": "117",
      "page": 11
    },
    {
      "level": "H5",
      "text": "108",
      "page": 11
    },
    {
      "level": "H5",
      "text": "134",
      "page": 11
    },
    {
      "level": "H5",
      "text": "137",
      "page": 11
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 12
    },
    {
      "level": "H5",
      "text": "139",
      "page": 12
    },
    {
      "level": "H5",
      "text": "142",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.5.3",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Chordal Graphs",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Partially Directed Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.6.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.6.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Summary and Discussion",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 12
    },
    {
      "level": "H5",
      "text": "152",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Conditional Random Fields",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Chain Graph Models (cid:63)",
      "page": 12
    },
    {
      "level": "H5",
      "text": "151",
      "page": 12
    },
    {
      "level": "H5",
      "text": "153",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.6",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.7",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.8",
      "page": 12
    },
    {
      "level": "H5",
      "text": "4.9",
      "page": 12
    },
    {
      "level": "H5",
      "text": "142",
      "page": 12
    },
    {
      "level": "H5",
      "text": "148",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5 Local Probabilistic Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "157",
      "page": 12
    },
    {
      "level": "H5",
      "text": "157",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.3",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.4",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.5",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.6",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.7",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.8",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.9",
      "page": 12
    },
    {
      "level": "H5",
      "text": "158",
      "page": 12
    },
    {
      "level": "H5",
      "text": "162",
      "page": 12
    },
    {
      "level": "H5",
      "text": "162",
      "page": 12
    },
    {
      "level": "H5",
      "text": "171",
      "page": 12
    },
    {
      "level": "H5",
      "text": "158",
      "page": 12
    },
    {
      "level": "H5",
      "text": "159",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Representation",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Independencies",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Tabular CPDs",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Deterministic CPDs",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.2.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.2.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Context-Speciﬁc CPDs",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.3.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Representation",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Independencies",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.3.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Independence of Causal Inﬂuence",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.4.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.4.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.4.3",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.4.4",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Continuous Variables",
      "page": 12
    },
    {
      "level": "H5",
      "text": "5.5.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Conditional Bayesian Networks",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 12
    },
    {
      "level": "H5",
      "text": "193",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 12
    },
    {
      "level": "H5",
      "text": "The Noisy-Or Model",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Generalized Linear Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "The General Formulation",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Independencies",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Hybrid Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "189",
      "page": 12
    },
    {
      "level": "H5",
      "text": "185",
      "page": 12
    },
    {
      "level": "H5",
      "text": "195",
      "page": 12
    },
    {
      "level": "H5",
      "text": "184",
      "page": 12
    },
    {
      "level": "H5",
      "text": "194",
      "page": 12
    },
    {
      "level": "H5",
      "text": "175",
      "page": 12
    },
    {
      "level": "H5",
      "text": "175",
      "page": 12
    },
    {
      "level": "H5",
      "text": "178",
      "page": 12
    },
    {
      "level": "H5",
      "text": "182",
      "page": 12
    },
    {
      "level": "H5",
      "text": "191",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6 Template-Based Representations",
      "page": 12
    },
    {
      "level": "H5",
      "text": "199",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.3",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.4",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.5",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.6",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.7",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.8",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.9",
      "page": 12
    },
    {
      "level": "H5",
      "text": "201",
      "page": 12
    },
    {
      "level": "H5",
      "text": "199",
      "page": 12
    },
    {
      "level": "H5",
      "text": "207",
      "page": 12
    },
    {
      "level": "H5",
      "text": "202",
      "page": 12
    },
    {
      "level": "H5",
      "text": "200",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Basic Assumptions",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Dynamic Bayesian Networks",
      "page": 12
    },
    {
      "level": "H5",
      "text": "State-Observation Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Temporal Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.2.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.2.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.2.3",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Template Variables and Template Factors",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Directed Probabilistic Models for Object-Relational Domains",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.4.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.4.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Undirected Representation",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Structural Uncertainty (cid:63)",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.6.1",
      "page": 12
    },
    {
      "level": "H5",
      "text": "6.6.2",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 12
    },
    {
      "level": "H5",
      "text": "240",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 12
    },
    {
      "level": "H5",
      "text": "232",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Relational Uncertainty",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Object Uncertainty",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Plate Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "Probabilistic Relational Models",
      "page": 12
    },
    {
      "level": "H5",
      "text": "228",
      "page": 12
    },
    {
      "level": "H5",
      "text": "233",
      "page": 12
    },
    {
      "level": "H5",
      "text": "235",
      "page": 12
    },
    {
      "level": "H5",
      "text": "222",
      "page": 12
    },
    {
      "level": "H5",
      "text": "243",
      "page": 12
    },
    {
      "level": "H5",
      "text": "242",
      "page": 12
    },
    {
      "level": "H5",
      "text": "216",
      "page": 12
    },
    {
      "level": "H5",
      "text": "212",
      "page": 12
    },
    {
      "level": "H5",
      "text": "216",
      "page": 12
    },
    {
      "level": "H5",
      "text": "xii",
      "page": 13
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7 Gaussian Network Models",
      "page": 13
    },
    {
      "level": "H5",
      "text": "247",
      "page": 13
    },
    {
      "level": "H5",
      "text": "247",
      "page": 13
    },
    {
      "level": "H5",
      "text": "247",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Basic Parameterization",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Operations on Gaussians",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Independencies in Gaussians",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Multivariate Gaussians",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.1.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.1.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.1.3",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Gaussian Bayesian Networks",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Gaussian Markov Random Fields",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 13
    },
    {
      "level": "H5",
      "text": "257",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 13
    },
    {
      "level": "H5",
      "text": "258",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 13
    },
    {
      "level": "H5",
      "text": "258",
      "page": 13
    },
    {
      "level": "H5",
      "text": "251",
      "page": 13
    },
    {
      "level": "H5",
      "text": "254",
      "page": 13
    },
    {
      "level": "H5",
      "text": "249",
      "page": 13
    },
    {
      "level": "H5",
      "text": "250",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8 The Exponential Family",
      "page": 13
    },
    {
      "level": "H5",
      "text": "261",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Linear Exponential Families",
      "page": 13
    },
    {
      "level": "H5",
      "text": "266",
      "page": 13
    },
    {
      "level": "H5",
      "text": "266",
      "page": 13
    },
    {
      "level": "H5",
      "text": "263",
      "page": 13
    },
    {
      "level": "H5",
      "text": "261",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 13
    },
    {
      "level": "H5",
      "text": "261",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Exponential Families",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.2.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Factored Exponential Families",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Product Distributions",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.3.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.3.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Bayesian Networks",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Entropy and Relative Entropy",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.4.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.4.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Projections",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Comparison",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.5.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "M-Projections",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.5.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "I-Projections",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.5.3",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 13
    },
    {
      "level": "H5",
      "text": "282",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 13
    },
    {
      "level": "H5",
      "text": "283",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Entropy",
      "page": 13
    },
    {
      "level": "H5",
      "text": "269",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Relative Entropy",
      "page": 13
    },
    {
      "level": "H5",
      "text": "273",
      "page": 13
    },
    {
      "level": "H5",
      "text": "283",
      "page": 13
    },
    {
      "level": "H5",
      "text": "274",
      "page": 13
    },
    {
      "level": "H5",
      "text": "277",
      "page": 13
    },
    {
      "level": "H5",
      "text": "282",
      "page": 13
    },
    {
      "level": "H5",
      "text": "267",
      "page": 13
    },
    {
      "level": "H5",
      "text": "269",
      "page": 13
    },
    {
      "level": "H5",
      "text": "272",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.3",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.4",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.5",
      "page": 13
    },
    {
      "level": "H5",
      "text": "7.6",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.3",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.4",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.5",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.6",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.7",
      "page": 13
    },
    {
      "level": "H5",
      "text": "8.8",
      "page": 13
    },
    {
      "level": "H4",
      "text": "Inference",
      "page": 13
    },
    {
      "level": "H4",
      "text": "285",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "288",
      "page": 13
    },
    {
      "level": "H5",
      "text": "288",
      "page": 13
    },
    {
      "level": "H5",
      "text": "287",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.3",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Analysis of Exact Inference",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Analysis of Approximate Inference",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9 Exact Inference: Variable Elimination",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Analysis of Complexity",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.1.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.1.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Variable Elimination: The Basic Ideas",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Variable Elimination",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.3.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.3.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Complexity and Graph Structure: Variable Elimination",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.4.1",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.4.2",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.4.3",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Conditioning ￿",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Simple Analysis",
      "page": 13
    },
    {
      "level": "H5",
      "text": "306",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Graph-Theoretic Analysis",
      "page": 13
    },
    {
      "level": "H5",
      "text": "306",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Finding Elimination Orderings ￿",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Basic Elimination",
      "page": 13
    },
    {
      "level": "H5",
      "text": "Dealing with Evidence",
      "page": 13
    },
    {
      "level": "H5",
      "text": "290",
      "page": 13
    },
    {
      "level": "H5",
      "text": "296",
      "page": 13
    },
    {
      "level": "H5",
      "text": "303",
      "page": 13
    },
    {
      "level": "H5",
      "text": "292",
      "page": 13
    },
    {
      "level": "H5",
      "text": "297",
      "page": 13
    },
    {
      "level": "H5",
      "text": "310",
      "page": 13
    },
    {
      "level": "H5",
      "text": "315",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.5",
      "page": 13
    },
    {
      "level": "H5",
      "text": "9.4",
      "page": 13
    },
    {
      "level": "H5",
      "text": "305",
      "page": 13
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 14
    },
    {
      "level": "H5",
      "text": "xiii",
      "page": 14
    },
    {
      "level": "H5",
      "text": "318",
      "page": 14
    },
    {
      "level": "H5",
      "text": "The Conditioning Algorithm",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Conditioning and Variable Elimination",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Graph-Theoretic Analysis",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Improved Conditioning",
      "page": 14
    },
    {
      "level": "H5",
      "text": "323",
      "page": 14
    },
    {
      "level": "H5",
      "text": "322",
      "page": 14
    },
    {
      "level": "H5",
      "text": "315",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.5.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.5.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.5.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.5.4",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Inference with Structured CPDs ￿",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.6.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.6.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.6.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Summary and Discussion",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 14
    },
    {
      "level": "H5",
      "text": "338",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 14
    },
    {
      "level": "H5",
      "text": "335",
      "page": 14
    },
    {
      "level": "H5",
      "text": "337",
      "page": 14
    },
    {
      "level": "H5",
      "text": "336",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Independence of Causal Inﬂuence",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Context-Speciﬁc Independence",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Discussion",
      "page": 14
    },
    {
      "level": "H5",
      "text": "325",
      "page": 14
    },
    {
      "level": "H5",
      "text": "325",
      "page": 14
    },
    {
      "level": "H5",
      "text": "329",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.6",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.7",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.8",
      "page": 14
    },
    {
      "level": "H5",
      "text": "9.9",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10 Exact Inference: Clique Trees",
      "page": 14
    },
    {
      "level": "H5",
      "text": "345",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Variable Elimination and Clique Trees",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.1.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.1.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Cluster Graphs",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Clique Trees",
      "page": 14
    },
    {
      "level": "H5",
      "text": "346",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.2 Message Passing: Sum Product",
      "page": 14
    },
    {
      "level": "H5",
      "text": "346",
      "page": 14
    },
    {
      "level": "H5",
      "text": "348",
      "page": 14
    },
    {
      "level": "H5",
      "text": "345",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.2.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.2.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.2.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Variable Elimination in a Clique Tree",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Clique Tree Calibration",
      "page": 14
    },
    {
      "level": "H5",
      "text": "A Calibrated Clique Tree as a Distribution",
      "page": 14
    },
    {
      "level": "H5",
      "text": "355",
      "page": 14
    },
    {
      "level": "H5",
      "text": "349",
      "page": 14
    },
    {
      "level": "H5",
      "text": "361",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.3 Message Passing: Belief Update",
      "page": 14
    },
    {
      "level": "H5",
      "text": "364",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Message Passing with Division",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Equivalence of Sum-Product and Belief Update Messages",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Answering Queries",
      "page": 14
    },
    {
      "level": "H5",
      "text": "369",
      "page": 14
    },
    {
      "level": "H5",
      "text": "364",
      "page": 14
    },
    {
      "level": "H5",
      "text": "368",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.3.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.3.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.3.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Constructing a Clique Tree",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.4.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.4.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "376",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 14
    },
    {
      "level": "H5",
      "text": "378",
      "page": 14
    },
    {
      "level": "H5",
      "text": "377",
      "page": 14
    },
    {
      "level": "H5",
      "text": "372",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Clique Trees from Variable Elimination",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Clique Trees from Chordal Graphs",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.4",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.5",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.6",
      "page": 14
    },
    {
      "level": "H5",
      "text": "10.7",
      "page": 14
    },
    {
      "level": "H5",
      "text": "382",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Exact Inference Revisited ￿",
      "page": 14
    },
    {
      "level": "H5",
      "text": "The Energy Functional",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Optimizing the Energy Functional",
      "page": 14
    },
    {
      "level": "H5",
      "text": "384",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "381",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Inference as Optimization",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 14
    },
    {
      "level": "H5",
      "text": "381",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.1.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.1.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.1.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Exact Inference as Optimization",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.2.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.2.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Propagation-Based Approximation",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.3.1",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.3.2",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.3.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.3.4",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.3.5",
      "page": 14
    },
    {
      "level": "H5",
      "text": "11.3",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Fixed-Point Characterization",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Inference as Optimization",
      "page": 14
    },
    {
      "level": "H5",
      "text": "391",
      "page": 14
    },
    {
      "level": "H5",
      "text": "A Simple Example",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Cluster-Graph Belief Propagation",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Properties of Cluster-Graph Belief Propagation",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Analyzing Convergence ￿",
      "page": 14
    },
    {
      "level": "H5",
      "text": "Constructing Cluster Graphs",
      "page": 14
    },
    {
      "level": "H5",
      "text": "396",
      "page": 14
    },
    {
      "level": "H5",
      "text": "404",
      "page": 14
    },
    {
      "level": "H5",
      "text": "401",
      "page": 14
    },
    {
      "level": "H5",
      "text": "388",
      "page": 14
    },
    {
      "level": "H5",
      "text": "390",
      "page": 14
    },
    {
      "level": "H5",
      "text": "391",
      "page": 14
    },
    {
      "level": "H5",
      "text": "386",
      "page": 14
    },
    {
      "level": "H5",
      "text": "399",
      "page": 14
    },
    {
      "level": "H5",
      "text": "372",
      "page": 14
    },
    {
      "level": "H5",
      "text": "374",
      "page": 14
    },
    {
      "level": "H5",
      "text": "386",
      "page": 14
    },
    {
      "level": "H5",
      "text": "xiv",
      "page": 15
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 15
    },
    {
      "level": "H5",
      "text": "414",
      "page": 15
    },
    {
      "level": "H5",
      "text": "430",
      "page": 15
    },
    {
      "level": "H5",
      "text": "433",
      "page": 15
    },
    {
      "level": "H5",
      "text": "436",
      "page": 15
    },
    {
      "level": "H5",
      "text": "411",
      "page": 15
    },
    {
      "level": "H5",
      "text": "431",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Variational Analysis",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Other Entropy Approximations (cid:63)",
      "page": 15
    },
    {
      "level": "H5",
      "text": "428",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Discussion",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Factorized Messages",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Approximate Message Computation",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Inference with Approximate Messages",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Expectation Propagation",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Variational Analysis",
      "page": 15
    },
    {
      "level": "H5",
      "text": "448",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Discussion",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.3.6",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.3.7",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.3.8",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Propagation with Approximate Messages (cid:63)",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4.3",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4.4",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4.5",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4.6",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Structured Variational Approximations",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.5.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.5.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.5.3",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Summary and Discussion",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 15
    },
    {
      "level": "H5",
      "text": "The Mean Field Approximation",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Structured Approximations",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Local Variational Methods (cid:63)",
      "page": 15
    },
    {
      "level": "H5",
      "text": "469",
      "page": 15
    },
    {
      "level": "H5",
      "text": "456",
      "page": 15
    },
    {
      "level": "H5",
      "text": "445",
      "page": 15
    },
    {
      "level": "H5",
      "text": "442",
      "page": 15
    },
    {
      "level": "H5",
      "text": "473",
      "page": 15
    },
    {
      "level": "H5",
      "text": "475",
      "page": 15
    },
    {
      "level": "H5",
      "text": "477",
      "page": 15
    },
    {
      "level": "H5",
      "text": "448",
      "page": 15
    },
    {
      "level": "H5",
      "text": "449",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.4",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.5",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.6",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.7",
      "page": 15
    },
    {
      "level": "H5",
      "text": "11.8",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12 Particle-Based Approximate Inference",
      "page": 15
    },
    {
      "level": "H5",
      "text": "487",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "488",
      "page": 15
    },
    {
      "level": "H5",
      "text": "488",
      "page": 15
    },
    {
      "level": "H5",
      "text": "490",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Sampling from a Bayesian Network",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Analysis of Error",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Conditional Probability Queries",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Forward Sampling",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.1.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.1.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.1.3",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Likelihood Weighting and Importance Sampling",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Likelihood Weighting: Intuition",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.2.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Importance Sampling",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.2.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Importance Sampling for Bayesian Networks",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.2.3",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Importance Sampling Revisited",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.2.4",
      "page": 15
    },
    {
      "level": "H5",
      "text": "504",
      "page": 15
    },
    {
      "level": "H5",
      "text": "492",
      "page": 15
    },
    {
      "level": "H5",
      "text": "494",
      "page": 15
    },
    {
      "level": "H5",
      "text": "491",
      "page": 15
    },
    {
      "level": "H5",
      "text": "492",
      "page": 15
    },
    {
      "level": "H5",
      "text": "498",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.3 Markov Chain Monte Carlo Methods",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Gibbs Sampling Algorithm",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Markov Chains",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Gibbs Sampling Revisited",
      "page": 15
    },
    {
      "level": "H5",
      "text": "A Broader Class of Markov Chains (cid:63)",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Using a Markov Chain",
      "page": 15
    },
    {
      "level": "H5",
      "text": "505",
      "page": 15
    },
    {
      "level": "H5",
      "text": "505",
      "page": 15
    },
    {
      "level": "H5",
      "text": "507",
      "page": 15
    },
    {
      "level": "H5",
      "text": "518",
      "page": 15
    },
    {
      "level": "H5",
      "text": "512",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.3.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.3.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.3.3",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.3.4",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.3.5",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Collapsed Particles",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.4.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.4.2",
      "page": 15
    },
    {
      "level": "H5",
      "text": "526",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Collapsed Likelihood Weighting (cid:63)",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Collapsed MCMC",
      "page": 15
    },
    {
      "level": "H5",
      "text": "531",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.4",
      "page": 15
    },
    {
      "level": "H5",
      "text": "515",
      "page": 15
    },
    {
      "level": "H5",
      "text": "527",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.5 Deterministic Search Methods (cid:63)",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.6",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.7",
      "page": 15
    },
    {
      "level": "H5",
      "text": "12.8",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 15
    },
    {
      "level": "H5",
      "text": "540",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 15
    },
    {
      "level": "H5",
      "text": "544",
      "page": 15
    },
    {
      "level": "H5",
      "text": "541",
      "page": 15
    },
    {
      "level": "H5",
      "text": "536",
      "page": 15
    },
    {
      "level": "H5",
      "text": "13 MAP Inference",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Overview",
      "page": 15
    },
    {
      "level": "H5",
      "text": "13.1.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "13.1",
      "page": 15
    },
    {
      "level": "H5",
      "text": "551",
      "page": 15
    },
    {
      "level": "H5",
      "text": "551",
      "page": 15
    },
    {
      "level": "H5",
      "text": "Computational Complexity",
      "page": 15
    },
    {
      "level": "H5",
      "text": "551",
      "page": 15
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.1.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Overview of Solution Methods",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Variable Elimination for (Marginal) MAP",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.2.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.2.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.2.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Max-Product Variable Elimination",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Finding the Most Probable Assignment",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Variable Elimination for Marginal MAP (cid:63)",
      "page": 16
    },
    {
      "level": "H5",
      "text": "552",
      "page": 16
    },
    {
      "level": "H5",
      "text": "554",
      "page": 16
    },
    {
      "level": "H5",
      "text": "554",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.3 Max-Product in Clique Trees",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.3.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.3.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.3.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "562",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Computing Max-Marginals",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Message Passing as Reparameterization",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Decoding Max-Marginals",
      "page": 16
    },
    {
      "level": "H5",
      "text": "565",
      "page": 16
    },
    {
      "level": "H5",
      "text": "562",
      "page": 16
    },
    {
      "level": "H5",
      "text": "556",
      "page": 16
    },
    {
      "level": "H5",
      "text": "559",
      "page": 16
    },
    {
      "level": "H5",
      "text": "564",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.4 Max-Product Belief Propagation in Loopy Cluster Graphs",
      "page": 16
    },
    {
      "level": "H5",
      "text": "567",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Standard Max-Product Message Passing",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Max-Product BP with Counting Numbers (cid:63)",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Discussion",
      "page": 16
    },
    {
      "level": "H5",
      "text": "575",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.4.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.4.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.4.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "567",
      "page": 16
    },
    {
      "level": "H5",
      "text": "572",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.5 MAP as a Linear Optimization Problem (cid:63)",
      "page": 16
    },
    {
      "level": "H5",
      "text": "The Integer Program Formulation",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Linear Programming Relaxation",
      "page": 16
    },
    {
      "level": "H5",
      "text": "581",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Low-Temperature Limits",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.5.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.5.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.5.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.6 Using Graph Cuts for MAP",
      "page": 16
    },
    {
      "level": "H5",
      "text": "588",
      "page": 16
    },
    {
      "level": "H5",
      "text": "577",
      "page": 16
    },
    {
      "level": "H5",
      "text": "577",
      "page": 16
    },
    {
      "level": "H5",
      "text": "579",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Inference Using Graph Cuts",
      "page": 16
    },
    {
      "level": "H5",
      "text": "592",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Nonbinary Variables",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.6.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.6.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Local Search Algorithms (cid:63)",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 16
    },
    {
      "level": "H5",
      "text": "597",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 16
    },
    {
      "level": "H5",
      "text": "598",
      "page": 16
    },
    {
      "level": "H5",
      "text": "595",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.7",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.8",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.9",
      "page": 16
    },
    {
      "level": "H5",
      "text": "13.10 Exercises",
      "page": 16
    },
    {
      "level": "H5",
      "text": "601",
      "page": 16
    },
    {
      "level": "H5",
      "text": "588",
      "page": 16
    },
    {
      "level": "H5",
      "text": "608",
      "page": 16
    },
    {
      "level": "H5",
      "text": "605",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "605",
      "page": 16
    },
    {
      "level": "H5",
      "text": "605",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Challenges",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Discretization",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Overview",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14 Inference in Hybrid Networks",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.1.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.1.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.1.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Variable Elimination in Gaussian Networks",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.2.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.2.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.2.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "606",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "607",
      "page": 16
    },
    {
      "level": "H5",
      "text": "611",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.3 Hybrid Networks",
      "page": 16
    },
    {
      "level": "H5",
      "text": "609",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Canonical Forms",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Sum-Product Algorithms",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Gaussian Belief Propagation",
      "page": 16
    },
    {
      "level": "H5",
      "text": "615",
      "page": 16
    },
    {
      "level": "H5",
      "text": "The Difficulties",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Factor Operations for Hybrid Gaussian Networks",
      "page": 16
    },
    {
      "level": "H5",
      "text": "EP for CLG Networks",
      "page": 16
    },
    {
      "level": "H5",
      "text": "621",
      "page": 16
    },
    {
      "level": "H5",
      "text": "An “Exact” CLG Algorithm (cid:63)",
      "page": 16
    },
    {
      "level": "H5",
      "text": "626",
      "page": 16
    },
    {
      "level": "H5",
      "text": "612",
      "page": 16
    },
    {
      "level": "H5",
      "text": "615",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.3.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.3.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.3.3",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.3.4",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Nonlinear Dependencies",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.4.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.4.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Particle-Based Approximation Methods",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.5.1",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.5.2",
      "page": 16
    },
    {
      "level": "H5",
      "text": "630",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Sampling in Continuous Spaces",
      "page": 16
    },
    {
      "level": "H5",
      "text": "642",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Forward Sampling in Bayesian Networks",
      "page": 16
    },
    {
      "level": "H5",
      "text": "643",
      "page": 16
    },
    {
      "level": "H5",
      "text": "642",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.4",
      "page": 16
    },
    {
      "level": "H5",
      "text": "14.5",
      "page": 16
    },
    {
      "level": "H5",
      "text": "618",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Linearization",
      "page": 16
    },
    {
      "level": "H5",
      "text": "Expectation Propagation with Gaussian Approximation",
      "page": 16
    },
    {
      "level": "H5",
      "text": "631",
      "page": 16
    },
    {
      "level": "H5",
      "text": "637",
      "page": 16
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 17
    },
    {
      "level": "H5",
      "text": "646",
      "page": 17
    },
    {
      "level": "H5",
      "text": "653",
      "page": 17
    },
    {
      "level": "H5",
      "text": "654",
      "page": 17
    },
    {
      "level": "H5",
      "text": "xvi",
      "page": 17
    },
    {
      "level": "H5",
      "text": "14.6",
      "page": 17
    },
    {
      "level": "H5",
      "text": "14.7",
      "page": 17
    },
    {
      "level": "H5",
      "text": "14.8",
      "page": 17
    },
    {
      "level": "H5",
      "text": "MCMC Methods",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Collapsed Particles",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Nonparametric Message Passing",
      "page": 17
    },
    {
      "level": "H5",
      "text": "645",
      "page": 17
    },
    {
      "level": "H5",
      "text": "644",
      "page": 17
    },
    {
      "level": "H5",
      "text": "14.5.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "14.5.4",
      "page": 17
    },
    {
      "level": "H5",
      "text": "14.5.5",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Summary and Discussion",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 17
    },
    {
      "level": "H5",
      "text": "649",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 17
    },
    {
      "level": "H5",
      "text": "646",
      "page": 17
    },
    {
      "level": "H5",
      "text": "647",
      "page": 17
    },
    {
      "level": "H5",
      "text": "651",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15 Inference in Temporal Models",
      "page": 17
    },
    {
      "level": "H5",
      "text": "652",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Inference Tasks",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Exact Inference",
      "page": 17
    },
    {
      "level": "H5",
      "text": "653",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Filtering in State-Observation Models",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.2.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Filtering as Clique Tree Propagation",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.2.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Clique Tree Inference in DBNs",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.2.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.2.4",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Entanglement",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Approximate Inference",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.3.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.3.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.3.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.3.4",
      "page": 17
    },
    {
      "level": "H5",
      "text": "675",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.4 Hybrid DBNs",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Continuous Models",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.4.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Hybrid Models",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.4.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 17
    },
    {
      "level": "H5",
      "text": "688",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 17
    },
    {
      "level": "H5",
      "text": "692",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Key Ideas",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Factored Belief State Methods",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Particle Filtering",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Deterministic Search Techniques",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.5",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.6",
      "page": 17
    },
    {
      "level": "H5",
      "text": "15.7",
      "page": 17
    },
    {
      "level": "H5",
      "text": "656",
      "page": 17
    },
    {
      "level": "H5",
      "text": "661",
      "page": 17
    },
    {
      "level": "H5",
      "text": "690",
      "page": 17
    },
    {
      "level": "H5",
      "text": "665",
      "page": 17
    },
    {
      "level": "H5",
      "text": "683",
      "page": 17
    },
    {
      "level": "H5",
      "text": "676",
      "page": 17
    },
    {
      "level": "H5",
      "text": "661",
      "page": 17
    },
    {
      "level": "H5",
      "text": "655",
      "page": 17
    },
    {
      "level": "H5",
      "text": "663",
      "page": 17
    },
    {
      "level": "H5",
      "text": "675",
      "page": 17
    },
    {
      "level": "H4",
      "text": "III Learning",
      "page": 17
    },
    {
      "level": "H4",
      "text": "695",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16 Learning Graphical Models: Overview",
      "page": 17
    },
    {
      "level": "H5",
      "text": "697",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.1 Motivation",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "697",
      "page": 17
    },
    {
      "level": "H5",
      "text": "698",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Goals of Learning",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.2.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.2.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.2.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Learning as Optimization",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.3.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.3.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Learning Tasks",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.4.1",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.4.2",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.4.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 17
    },
    {
      "level": "H5",
      "text": "711",
      "page": 17
    },
    {
      "level": "H5",
      "text": "715",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.3",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.4",
      "page": 17
    },
    {
      "level": "H5",
      "text": "16.5",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Density Estimation",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Speciﬁc Prediction Tasks",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Knowledge Discovery",
      "page": 17
    },
    {
      "level": "H5",
      "text": "698",
      "page": 17
    },
    {
      "level": "H5",
      "text": "700",
      "page": 17
    },
    {
      "level": "H5",
      "text": "701",
      "page": 17
    },
    {
      "level": "H5",
      "text": "702",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Empirical Risk and Overﬁtting",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Discriminative versus Generative Training",
      "page": 17
    },
    {
      "level": "H5",
      "text": "703",
      "page": 17
    },
    {
      "level": "H5",
      "text": "709",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Model Constraints",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Data Observability",
      "page": 17
    },
    {
      "level": "H5",
      "text": "Taxonomy of Learning Tasks",
      "page": 17
    },
    {
      "level": "H5",
      "text": "712",
      "page": 17
    },
    {
      "level": "H5",
      "text": "712",
      "page": 17
    },
    {
      "level": "H5",
      "text": "714",
      "page": 17
    },
    {
      "level": "H5",
      "text": "17 Parameter Estimation",
      "page": 17
    },
    {
      "level": "H5",
      "text": "717",
      "page": 17
    },
    {
      "level": "H5",
      "text": "17.1 Maximum Likelihood Estimation",
      "page": 17
    },
    {
      "level": "H5",
      "text": "717",
      "page": 17
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 18
    },
    {
      "level": "H5",
      "text": "xvii",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.1.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.1.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "The Thumbtack Example",
      "page": 18
    },
    {
      "level": "H5",
      "text": "The Maximum Likelihood Principle",
      "page": 18
    },
    {
      "level": "H5",
      "text": "717",
      "page": 18
    },
    {
      "level": "H5",
      "text": "720",
      "page": 18
    },
    {
      "level": "H5",
      "text": "731",
      "page": 18
    },
    {
      "level": "H5",
      "text": "742",
      "page": 18
    },
    {
      "level": "H5",
      "text": "737",
      "page": 18
    },
    {
      "level": "H5",
      "text": "724",
      "page": 18
    },
    {
      "level": "H5",
      "text": "725",
      "page": 18
    },
    {
      "level": "H5",
      "text": "733",
      "page": 18
    },
    {
      "level": "H5",
      "text": "733",
      "page": 18
    },
    {
      "level": "H5",
      "text": "728",
      "page": 18
    },
    {
      "level": "H5",
      "text": "722",
      "page": 18
    },
    {
      "level": "H5",
      "text": "723",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.2 MLE for Bayesian Networks",
      "page": 18
    },
    {
      "level": "H5",
      "text": "A Simple Example",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Global Likelihood Decomposition",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Table-CPDs",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Gaussian Bayesian Networks (cid:63)",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Maximum Likelihood Estimation as M-Projection (cid:63)",
      "page": 18
    },
    {
      "level": "H5",
      "text": "741",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Parameter Independence and Global Decomposition",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Local Decomposition",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Priors for Bayesian Network Learning",
      "page": 18
    },
    {
      "level": "H5",
      "text": "MAP Estimation (cid:63)",
      "page": 18
    },
    {
      "level": "H5",
      "text": "The Thumbtack Example Revisited",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Priors and Posteriors",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.2.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.2.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.2.3",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.2.4",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.2.5",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Bayesian Parameter Estimation",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.3.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.3.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Bayesian Parameter Estimation in Bayesian Networks",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.4.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.4.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.4.3",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.4.4",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Learning Models with Shared Parameters",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.5.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.5.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.5.3",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.5.4",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Generalization Analysis (cid:63)",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Asymptotic Analysis",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.6.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "770",
      "page": 18
    },
    {
      "level": "H5",
      "text": "PAC-Bounds",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.6.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 18
    },
    {
      "level": "H5",
      "text": "776",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Global Parameter Sharing",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Local Parameter Sharing",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Bayesian Inference with Shared Parameters",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Hierarchical Priors (cid:63)",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.3",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.4",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.5",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.6",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.7",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.8",
      "page": 18
    },
    {
      "level": "H5",
      "text": "17.9",
      "page": 18
    },
    {
      "level": "H5",
      "text": "755",
      "page": 18
    },
    {
      "level": "H5",
      "text": "760",
      "page": 18
    },
    {
      "level": "H5",
      "text": "769",
      "page": 18
    },
    {
      "level": "H5",
      "text": "769",
      "page": 18
    },
    {
      "level": "H5",
      "text": "763",
      "page": 18
    },
    {
      "level": "H5",
      "text": "762",
      "page": 18
    },
    {
      "level": "H5",
      "text": "746",
      "page": 18
    },
    {
      "level": "H5",
      "text": "748",
      "page": 18
    },
    {
      "level": "H5",
      "text": "778",
      "page": 18
    },
    {
      "level": "H5",
      "text": "754",
      "page": 18
    },
    {
      "level": "H5",
      "text": "777",
      "page": 18
    },
    {
      "level": "H5",
      "text": "751",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18 Structure Learning in Bayesian Networks",
      "page": 18
    },
    {
      "level": "H5",
      "text": "783",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.4",
      "page": 18
    },
    {
      "level": "H5",
      "text": "783",
      "page": 18
    },
    {
      "level": "H5",
      "text": "785",
      "page": 18
    },
    {
      "level": "H5",
      "text": "786",
      "page": 18
    },
    {
      "level": "H5",
      "text": "786",
      "page": 18
    },
    {
      "level": "H5",
      "text": "787",
      "page": 18
    },
    {
      "level": "H5",
      "text": "790",
      "page": 18
    },
    {
      "level": "H5",
      "text": "783",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Problem Deﬁnition",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Overview of Methods",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.1.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.1.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Constraint-Based Approaches",
      "page": 18
    },
    {
      "level": "H5",
      "text": "General Framework",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.2.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.2.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Independence Tests",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Structure Scores",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.2",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.3",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.4",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.5",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.6",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.3.7",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Structure Search",
      "page": 18
    },
    {
      "level": "H5",
      "text": "18.4.1",
      "page": 18
    },
    {
      "level": "H5",
      "text": "804",
      "page": 18
    },
    {
      "level": "H5",
      "text": "807",
      "page": 18
    },
    {
      "level": "H5",
      "text": "791",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Likelihood Scores",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Bayesian Score",
      "page": 18
    },
    {
      "level": "H5",
      "text": "794",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Marginal Likelihood for a Single Variable",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Bayesian Score for Bayesian Networks",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Understanding the Bayesian Score",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Priors",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Score Equivalence (cid:63)",
      "page": 18
    },
    {
      "level": "H5",
      "text": "807",
      "page": 18
    },
    {
      "level": "H5",
      "text": "801",
      "page": 18
    },
    {
      "level": "H5",
      "text": "Learning Tree-Structured Networks",
      "page": 18
    },
    {
      "level": "H5",
      "text": "808",
      "page": 18
    },
    {
      "level": "H5",
      "text": "797",
      "page": 18
    },
    {
      "level": "H5",
      "text": "799",
      "page": 18
    },
    {
      "level": "H5",
      "text": "xviii",
      "page": 19
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 19
    },
    {
      "level": "H5",
      "text": "821",
      "page": 19
    },
    {
      "level": "H5",
      "text": "824",
      "page": 19
    },
    {
      "level": "H5",
      "text": "824",
      "page": 19
    },
    {
      "level": "H5",
      "text": "809",
      "page": 19
    },
    {
      "level": "H5",
      "text": "811",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Known Order",
      "page": 19
    },
    {
      "level": "H5",
      "text": "General Graphs",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Learning with Equivalence Classes (cid:63)",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Basic Theory",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Model Averaging Given an Order",
      "page": 19
    },
    {
      "level": "H5",
      "text": "The General Case",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.4.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.4.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.4.4",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Bayesian Model Averaging (cid:63)",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.5.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.5.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.5.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Learning Models with Additional Structure",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.6.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.6.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Summary and Discussion",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Learning with Local Structure",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Learning Template Models",
      "page": 19
    },
    {
      "level": "H5",
      "text": "838",
      "page": 19
    },
    {
      "level": "H5",
      "text": "840",
      "page": 19
    },
    {
      "level": "H5",
      "text": "828",
      "page": 19
    },
    {
      "level": "H5",
      "text": "843",
      "page": 19
    },
    {
      "level": "H5",
      "text": "837",
      "page": 19
    },
    {
      "level": "H5",
      "text": "826",
      "page": 19
    },
    {
      "level": "H5",
      "text": "832",
      "page": 19
    },
    {
      "level": "H5",
      "text": "833",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.5",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.6",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.7",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.8",
      "page": 19
    },
    {
      "level": "H5",
      "text": "18.9",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19 Partially Observed Data",
      "page": 19
    },
    {
      "level": "H5",
      "text": "849",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.4",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.5",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.6",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.7",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.8",
      "page": 19
    },
    {
      "level": "H5",
      "text": "849",
      "page": 19
    },
    {
      "level": "H5",
      "text": "862",
      "page": 19
    },
    {
      "level": "H5",
      "text": "856",
      "page": 19
    },
    {
      "level": "H5",
      "text": "863",
      "page": 19
    },
    {
      "level": "H5",
      "text": "860",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Likelihood of Data and Observation Models",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Decoupling of Observation Mechanism",
      "page": 19
    },
    {
      "level": "H5",
      "text": "The Likelihood Function",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Identiﬁability",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Foundations",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.1.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.1.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.1.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.1.4",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Parameter Estimation",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Gradient Ascent",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.2.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Expectation Maximization (EM)",
      "page": 19
    },
    {
      "level": "H5",
      "text": "868",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.2.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Comparison: Gradient Ascent versus EM",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.2.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.2.4",
      "page": 19
    },
    {
      "level": "H5",
      "text": "893",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Approximate Inference (cid:63)",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Bayesian Learning with Incomplete Data (cid:63)",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.3.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.3.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.3.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Structure Learning",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.4.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.4.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.4.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Learning Models with Hidden Variables",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.5.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.5.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "19.5.3",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 19
    },
    {
      "level": "H5",
      "text": "933",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 19
    },
    {
      "level": "H5",
      "text": "935",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Overview",
      "page": 19
    },
    {
      "level": "H5",
      "text": "897",
      "page": 19
    },
    {
      "level": "H5",
      "text": "MCMC Sampling",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Variational Bayesian Learning",
      "page": 19
    },
    {
      "level": "H5",
      "text": "908",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Scoring Structures",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Structure Search",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Structural EM",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Information Content of Hidden Variables",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Determining the Cardinality",
      "page": 19
    },
    {
      "level": "H5",
      "text": "Introducing Hidden Variables",
      "page": 19
    },
    {
      "level": "H5",
      "text": "909",
      "page": 19
    },
    {
      "level": "H5",
      "text": "899",
      "page": 19
    },
    {
      "level": "H5",
      "text": "930",
      "page": 19
    },
    {
      "level": "H5",
      "text": "920",
      "page": 19
    },
    {
      "level": "H5",
      "text": "904",
      "page": 19
    },
    {
      "level": "H5",
      "text": "928",
      "page": 19
    },
    {
      "level": "H5",
      "text": "897",
      "page": 19
    },
    {
      "level": "H5",
      "text": "925",
      "page": 19
    },
    {
      "level": "H5",
      "text": "934",
      "page": 19
    },
    {
      "level": "H5",
      "text": "917",
      "page": 19
    },
    {
      "level": "H5",
      "text": "849",
      "page": 19
    },
    {
      "level": "H5",
      "text": "853",
      "page": 19
    },
    {
      "level": "H5",
      "text": "887",
      "page": 19
    },
    {
      "level": "H5",
      "text": "926",
      "page": 19
    },
    {
      "level": "H5",
      "text": "20 Learning Undirected Models",
      "page": 19
    },
    {
      "level": "H5",
      "text": "20.1 Overview",
      "page": 19
    },
    {
      "level": "H5",
      "text": "20.2",
      "page": 19
    },
    {
      "level": "H5",
      "text": "943",
      "page": 19
    },
    {
      "level": "H5",
      "text": "The Likelihood Function",
      "page": 19
    },
    {
      "level": "H5",
      "text": "20.2.1",
      "page": 19
    },
    {
      "level": "H5",
      "text": "An Example",
      "page": 19
    },
    {
      "level": "H5",
      "text": "943",
      "page": 19
    },
    {
      "level": "H5",
      "text": "944",
      "page": 19
    },
    {
      "level": "H5",
      "text": "944",
      "page": 19
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 20
    },
    {
      "level": "H5",
      "text": "xix",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.2.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.2.3",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Form of the Likelihood Function",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Properties of the Likelihood Function",
      "page": 20
    },
    {
      "level": "H5",
      "text": "946",
      "page": 20
    },
    {
      "level": "H5",
      "text": "947",
      "page": 20
    },
    {
      "level": "H5",
      "text": "949",
      "page": 20
    },
    {
      "level": "H5",
      "text": "950",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.3 Maximum (Conditional) Likelihood Parameter Estimation",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Maximum Likelihood Estimation",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Conditionally Trained Models",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Learning with Missing Data",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.3.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.3.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.3.3",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.3.4 Maximum Entropy and Maximum Likelihood (cid:63)",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Parameter Priors and Regularization",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.4.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.4.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Learning with Approximate Inference",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.5.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "962",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Belief Propagation",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.5.2 MAP-Based Learning (cid:63)",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Local Priors",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Global Priors",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.4",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.5",
      "page": 20
    },
    {
      "level": "H5",
      "text": "958",
      "page": 20
    },
    {
      "level": "H5",
      "text": "961",
      "page": 20
    },
    {
      "level": "H5",
      "text": "958",
      "page": 20
    },
    {
      "level": "H5",
      "text": "967",
      "page": 20
    },
    {
      "level": "H5",
      "text": "954",
      "page": 20
    },
    {
      "level": "H5",
      "text": "961",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.6 Alternative Objectives",
      "page": 20
    },
    {
      "level": "H5",
      "text": "969",
      "page": 20
    },
    {
      "level": "H5",
      "text": "949",
      "page": 20
    },
    {
      "level": "H5",
      "text": "956",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Pseudolikelihood and Its Generalizations",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Contrastive Optimization Criteria",
      "page": 20
    },
    {
      "level": "H5",
      "text": "974",
      "page": 20
    },
    {
      "level": "H5",
      "text": "978",
      "page": 20
    },
    {
      "level": "H5",
      "text": "970",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Structure Learning Using Independence Tests",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Score-Based Learning: Hypothesis Spaces",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Objective Functions",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Optimization Task",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Evaluating Changes to the Model",
      "page": 20
    },
    {
      "level": "H5",
      "text": "985",
      "page": 20
    },
    {
      "level": "H5",
      "text": "982",
      "page": 20
    },
    {
      "level": "H5",
      "text": "992",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.7",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.6.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.6.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Structure Learning",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.7.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.7.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.7.3",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.7.4",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.7.5",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.8",
      "page": 20
    },
    {
      "level": "H5",
      "text": "996",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.9 Relevant Literature",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1001",
      "page": 20
    },
    {
      "level": "H5",
      "text": "20.10 Exercises",
      "page": 20
    },
    {
      "level": "H5",
      "text": "998",
      "page": 20
    },
    {
      "level": "H4",
      "text": "IV Actions and Decisions",
      "page": 20
    },
    {
      "level": "H4",
      "text": "1007",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21 Causality",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1009",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.1 Motivation and Overview",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1009",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.3",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Conditioning and Intervention",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Correlation and Causation",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1014",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.1.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.1.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Causal Models",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Structural Causal Identiﬁability",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.3.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.3.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Query Simpliﬁcation Rules",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Iterated Query Simpliﬁcation",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.4 Mechanisms and Response Variables (cid:63)",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.5",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.6",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1034",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1017",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1009",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1012",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1017",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1020",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1026",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Partial Identiﬁability in Functional Causal Models (cid:63)",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Counterfactual Queries (cid:63)",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.6.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.6.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Learning Causal Models",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.7.1",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.7.2",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Twinned Networks",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Bounds on Counterfactual Queries",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Learning Causal Models without Confounding Factors",
      "page": 20
    },
    {
      "level": "H5",
      "text": "Learning from Interventional Data",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1040",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1034",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1037",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1044",
      "page": 20
    },
    {
      "level": "H5",
      "text": "21.7",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1041",
      "page": 20
    },
    {
      "level": "H5",
      "text": "979",
      "page": 20
    },
    {
      "level": "H5",
      "text": "981",
      "page": 20
    },
    {
      "level": "H5",
      "text": "1031",
      "page": 20
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Dealing with Latent Variables (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Learning Functional Causal Models (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1048",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1051",
      "page": 21
    },
    {
      "level": "H5",
      "text": "21.7.3",
      "page": 21
    },
    {
      "level": "H5",
      "text": "21.7.4",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1053",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1055",
      "page": 21
    },
    {
      "level": "H5",
      "text": "21.8",
      "page": 21
    },
    {
      "level": "H5",
      "text": "21.9",
      "page": 21
    },
    {
      "level": "H5",
      "text": "21.10 Exercises",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22 Utilities and Decisions",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1054",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1059",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Decision Making Under Uncertainty",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1062",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Theoretical Justiﬁcation (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Foundations: Maximizing Expected Utility",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.1.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.1.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.2 Utility Curves",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.2.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.2.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.2.3",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Utility of Money",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Attitudes Toward Risk",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Rationality",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1066",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1065",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1064",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1067",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1059",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1059",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.3 Utility Elicitation",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1068",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Utility Elicitation Procedures",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Utility of Human Life",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.4 Utilities of Complex Outcomes",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.3.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.3.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1069",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1071",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1068",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Preference and Utility Independence (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Additive Independence Properties",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1074",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1071",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.4.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.4.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1081",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1084",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Exercises",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.5",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.6",
      "page": 21
    },
    {
      "level": "H5",
      "text": "22.7",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1082",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1085",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1085",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1088",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.1 Decision Trees",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23 Structured Decision Problems",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1085",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Representation",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Backward Induction Algorithm",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.1.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.1.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Inﬂuence Diagrams",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.2.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.2.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.2.3",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.2.4",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Backward Induction in Inﬂuence Diagrams",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.3.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.3.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Basic Representation",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Decision Rules",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Time and Recall",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Semantics and Optimality Criterion",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Decision Trees for Inﬂuence Diagrams",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Sum-Max-Sum Rule",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.4 Computing Expected Utilities",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.3",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1090",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1089",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1092",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1087",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.4.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.4.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.4.3",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1100",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1098",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1100",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Simple Variable Elimination",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Multiple Utility Variables: Simple Approaches",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Generalized Variable Elimination (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1107",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Optimizing a Single Decision Rule",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Iterated Optimization Algorithm",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Strategic Relevance and Global Optimality (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1108",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1103",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1107",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.5.1",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.5.2",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.5.3",
      "page": 21
    },
    {
      "level": "H5",
      "text": "Ignoring Irrelevant Information (cid:63)",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1119",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.5 Optimization in Inﬂuence Diagrams",
      "page": 21
    },
    {
      "level": "H5",
      "text": "23.6",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1093",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1095",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1096",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1102",
      "page": 21
    },
    {
      "level": "H5",
      "text": "1110",
      "page": 21
    },
    {
      "level": "H5",
      "text": "CONTENTS",
      "page": 22
    },
    {
      "level": "H5",
      "text": "xxi",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1121",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Single Observations",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Multiple Observations",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1122",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1124",
      "page": 22
    },
    {
      "level": "H5",
      "text": "23.7 Value of Information",
      "page": 22
    },
    {
      "level": "H5",
      "text": "23.7.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "23.7.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Summary",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1126",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Relevant Literature",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1130",
      "page": 22
    },
    {
      "level": "H5",
      "text": "23.8",
      "page": 22
    },
    {
      "level": "H5",
      "text": "23.9",
      "page": 22
    },
    {
      "level": "H5",
      "text": "23.10 Exercises",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1127",
      "page": 22
    },
    {
      "level": "H5",
      "text": "24 Epilogue",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1133",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A Background Material",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1137",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Compression and Entropy",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Conditional Entropy and Information",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Relative Entropy and Distances Between Distributions",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1139",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1137",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1140",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.3",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.4",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.5",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1144",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1137",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1143",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Information Theory",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.1.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.1.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.1.3",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Convergence Bounds",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Central Limit Theorem",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.2.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.2.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1145",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Convergence Bounds",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Algorithms and Algorithmic Complexity",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Basic Graph Algorithms",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.3.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Analysis of Algorithmic Complexity",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.3.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Dynamic Programming",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.3.3",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.3.4",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Complexity Theory",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Combinatorial Optimization and Search",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Optimization Problems",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.4.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Local Search",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.4.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.4.3",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Branch and Bound Search",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Continuous Optimization",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.5.1",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.5.2",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.5.3",
      "page": 22
    },
    {
      "level": "H5",
      "text": "A.5.4",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1163",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1167",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1160",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1150",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1146",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1149",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1154",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1154",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1161",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1171",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1147",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1146",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1154",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Characterizing Optima of a Continuous Function",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Gradient Ascent Methods",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Constrained Optimization",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Convex Duality",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1161",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Bibliography",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Notation Index",
      "page": 22
    },
    {
      "level": "H5",
      "text": "Subject Index",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1173",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1211",
      "page": 22
    },
    {
      "level": "H5",
      "text": "1215",
      "page": 22
    },
    {
      "level": "H2",
      "text": "Acknowledgments",
      "page": 24
    },
    {
      "level": "H5",
      "text": "This book owes a considerable debt of gratitude to the many people who contributed to its",
      "page": 24
    },
    {
      "level": "H5",
      "text": "creation, and to those who have inﬂuenced our work and our thinking over the years.",
      "page": 24
    },
    {
      "level": "H5",
      "text": "First and foremost, we want to thank our students, who, by asking the right questions, and",
      "page": 24
    },
    {
      "level": "H5",
      "text": "forcing us to formulate clear and precise answers, were directly responsible for the inception of",
      "page": 24
    },
    {
      "level": "H5",
      "text": "this book and for any clarity of presentation.",
      "page": 24
    },
    {
      "level": "H5",
      "text": "We have been fortunate to share the same mentors, who have had a signiﬁcant impact on",
      "page": 24
    },
    {
      "level": "H5",
      "text": "our development as researchers and as teachers: Joe Halpern, Stuart Russell. Much of our core",
      "page": 24
    },
    {
      "level": "H5",
      "text": "views on probabilistic models have been inﬂuenced by Judea Pearl. Judea through his persuasive",
      "page": 24
    },
    {
      "level": "H5",
      "text": "writing and vivid presentations inspired us, and many other researchers of our generation, to",
      "page": 24
    },
    {
      "level": "H5",
      "text": "plunge into research in this ﬁeld.",
      "page": 24
    },
    {
      "level": "H5",
      "text": "There are many people whose conversations with us have helped us in thinking through",
      "page": 24
    },
    {
      "level": "H5",
      "text": "some of the more difficult concepts in the book: Nando de Freitas, Gal Elidan, Dan Geiger,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Amir Globerson, Uri Lerner, Chris Meek, David Sontag, Yair Weiss, and Ramin Zabih. Others,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "in conversations and collaborations over the year, have also inﬂuenced our thinking and the",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Jeff Bilmes, Craig Boutilier, Moises Goldszmidt,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "presentation of the material: Pieter Abbeel,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Carlos Guestrin, David Heckerman, Eric Horvitz, Tommi Jaakkola, Michael Jordan, Kevin Murphy,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Andrew Ng, Ben Taskar, and Sebastian Thrun.",
      "page": 24
    },
    {
      "level": "H5",
      "text": "We especially want to acknowledge Gal Elidan for constant encouragement, valuable feedback,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "and logistic support at many critical junctions, throughout the long years of writing this book.",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Over the course of the years of work on this book, many people have contributed to it",
      "page": 24
    },
    {
      "level": "H5",
      "text": "by providing insights, engaging in enlightening discussions, and giving valuable feedback. It is",
      "page": 24
    },
    {
      "level": "H5",
      "text": "impossible to individually acknowledge all of the people who made such contributions. However,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "we speciﬁcally wish to express our gratitude to those people who read large parts of the book",
      "page": 24
    },
    {
      "level": "H5",
      "text": "and gave detailed feedback: Rahul Biswas, James Cussens, James Diebel, Yoni Donner, Tal El-",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Hay, Gal Elidan, Stanislav Funiak, Amir Globerson, Russ Greiner, Carlos Guestrin, Tim Heilman,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Geremy Heitz, Maureen Hillenmeyer, Ariel Jaimovich, Tommy Kaplan, Jonathan Laserson, Ken",
      "page": 24
    },
    {
      "level": "H5",
      "text": "Levine, Brian Milch, Kevin Murphy, Ben Packer, Ronald Parr, Dana Pe’er, and Christian Shelton.",
      "page": 24
    },
    {
      "level": "H5",
      "text": "We are deeply grateful to the following people, who contributed speciﬁc text and/or ﬁgures,",
      "page": 24
    },
    {
      "level": "H5",
      "text": "mostly to the case studies and concept boxes without which this book would be far less",
      "page": 24
    },
    {
      "level": "H5",
      "text": "interesting: Gal Elidan, to chapter 11, chapter 18, and chapter 19; Stephen Gould, to chapter 4",
      "page": 24
    },
    {
      "level": "H5",
      "text": "and chapter 13; Vladimir Jojic, to chapter 12; Jonathan Laserson, to chapter 19; Uri Lerner, to",
      "page": 24
    },
    {
      "level": "H5",
      "text": "chapter 14; Andrew McCallum and Charles Sutton, to chapter 4; Brian Milch, to chapter 6; Kevin",
      "page": 24
    },
    {
      "level": "H5",
      "text": "xxiv",
      "page": 25
    },
    {
      "level": "H5",
      "text": "Acknowledgments",
      "page": 25
    },
    {
      "level": "H5",
      "text": "Murphy, to chapter 15; and Benjamin Packer, to many of the exercises used throughout the book.",
      "page": 25
    },
    {
      "level": "H5",
      "text": "In addition, we are very grateful to Amir Globerson, David Sontag and Yair Weiss whose insights",
      "page": 25
    },
    {
      "level": "H5",
      "text": "on chapter 13 played a key role in the development of the material in that chapter.",
      "page": 25
    },
    {
      "level": "H5",
      "text": "Special thanks are due to Bob Prior at MIT Press who convinced us to go ahead with this",
      "page": 25
    },
    {
      "level": "H5",
      "text": "project and was constantly supportive, enthusiastic and patient in the face of the recurring",
      "page": 25
    },
    {
      "level": "H5",
      "text": "delays and missed deadlines. We thank Greg McNamee, our copy editor, and Mary Reilly, our",
      "page": 25
    },
    {
      "level": "H5",
      "text": "artist, for their help in improving this book considerably. We thank Chris Manning, for allowing",
      "page": 25
    },
    {
      "level": "H5",
      "text": "us to use his LATEX macros for typesetting this book, and for providing useful advice on how to",
      "page": 25
    },
    {
      "level": "H5",
      "text": "use them. And we thank Miles Davis for invaluable technical support.",
      "page": 25
    },
    {
      "level": "H5",
      "text": "We also wish to thank the many colleagues who used drafts of this book in teaching provided",
      "page": 25
    },
    {
      "level": "H5",
      "text": "enthusiastic feedback that encouraged us to continue this project at times where it seemed",
      "page": 25
    },
    {
      "level": "H5",
      "text": "unending. Sebastian Thrun deserves a special note of thanks, for forcing us to set a deadline for",
      "page": 25
    },
    {
      "level": "H5",
      "text": "completion of this book and to stick to it.",
      "page": 25
    },
    {
      "level": "H5",
      "text": "We also want to thank the past and present members of the DAGS group at Stanford, and the",
      "page": 25
    },
    {
      "level": "H5",
      "text": "Computational Biology group at the Hebrew University, many of whom also contributed ideas,",
      "page": 25
    },
    {
      "level": "H5",
      "text": "insights, and useful comments. We speciﬁcally want to thank them for bearing with us while",
      "page": 25
    },
    {
      "level": "H5",
      "text": "we devoted far too much of our time to working on this book.",
      "page": 25
    },
    {
      "level": "H5",
      "text": "Finally, noone deserves our thanks more than our long-suffering families — Natalie Anna",
      "page": 25
    },
    {
      "level": "H5",
      "text": "Koller Avida, Maya Rika Koller Avida, and Dan Avida; Lior, Roy, and Yael Friedman — for their",
      "page": 25
    },
    {
      "level": "H5",
      "text": "continued love, support, and patience, as they watched us work evenings and weekends to",
      "page": 25
    },
    {
      "level": "H5",
      "text": "complete this book. We could never have done this without you.",
      "page": 25
    },
    {
      "level": "H2",
      "text": "List of Figures",
      "page": 26
    },
    {
      "level": "H5",
      "text": "1.1",
      "page": 26
    },
    {
      "level": "H5",
      "text": "1.2",
      "page": 26
    },
    {
      "level": "H5",
      "text": "2.1",
      "page": 26
    },
    {
      "level": "H5",
      "text": "2.2",
      "page": 26
    },
    {
      "level": "H5",
      "text": "2.3",
      "page": 26
    },
    {
      "level": "H5",
      "text": "2.4",
      "page": 26
    },
    {
      "level": "H5",
      "text": "2.5",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.1",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.2",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.3",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.4",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.5",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.6",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.7",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.8",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.9",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.10",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.11",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.12",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.13",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.14",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.15",
      "page": 26
    },
    {
      "level": "H5",
      "text": "3.16",
      "page": 26
    },
    {
      "level": "H5",
      "text": "4.1",
      "page": 26
    },
    {
      "level": "H5",
      "text": "4.2",
      "page": 26
    },
    {
      "level": "H5",
      "text": "4.3",
      "page": 26
    },
    {
      "level": "H5",
      "text": "4.4",
      "page": 26
    },
    {
      "level": "H5",
      "text": "4.5",
      "page": 26
    },
    {
      "level": "H5",
      "text": "4.6",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Different perspectives on probabilistic graphical models",
      "page": 26
    },
    {
      "level": "H5",
      "text": "A reader’s guide to the structure and dependencies in this book",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Example of a joint distribution P (Intelligence, Grade)",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Example PDF of three Gaussian distributions",
      "page": 26
    },
    {
      "level": "H5",
      "text": "An example of a partially directed graph K",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Induced graphs and their upward closure",
      "page": 26
    },
    {
      "level": "H5",
      "text": "An example of a polytree",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Simple Bayesian networks for the student example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "The Bayesian network graph for a naive Bayes model",
      "page": 26
    },
    {
      "level": "H5",
      "text": "The Bayesian Network graph for the Student example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Student Bayesian network Bstudent with CPDs",
      "page": 26
    },
    {
      "level": "H5",
      "text": "The four possible two-edge trails",
      "page": 26
    },
    {
      "level": "H5",
      "text": "A simple example for the d-separation algorithm",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Skeletons and v-structures in a network",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Three minimal I-maps for PBstudent , induced by different orderings",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Network for the OneLetter example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Attempted Bayesian network models for the Misconception example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Simple example of compelled edges in an equivalence class.",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Rules for orienting edges in PDAG",
      "page": 26
    },
    {
      "level": "H5",
      "text": "More complex example of compelled edges in an equivalence class",
      "page": 26
    },
    {
      "level": "H5",
      "text": "A Bayesian network with qualitative inﬂuences",
      "page": 26
    },
    {
      "level": "H5",
      "text": "A simple network for a burglary alarm domain",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Illustration of the concept of a self-contained set",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Factors for the Misconception example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Joint distribution for the Misconception example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "An example of factor product",
      "page": 26
    },
    {
      "level": "H5",
      "text": "The cliques in two simple Markov networks",
      "page": 26
    },
    {
      "level": "H5",
      "text": "An example of factor reduction",
      "page": 26
    },
    {
      "level": "H5",
      "text": "Markov networks for the factors in an extended Student example",
      "page": 26
    },
    {
      "level": "H5",
      "text": "101",
      "page": 26
    },
    {
      "level": "H5",
      "text": "104",
      "page": 26
    },
    {
      "level": "H5",
      "text": "105",
      "page": 26
    },
    {
      "level": "H5",
      "text": "107",
      "page": 26
    },
    {
      "level": "H5",
      "text": "109",
      "page": 26
    },
    {
      "level": "H5",
      "text": "111",
      "page": 26
    },
    {
      "level": "H5",
      "text": "112",
      "page": 26
    },
    {
      "level": "H5",
      "text": "xxvi",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.7",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.8",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.9",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.10",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.11",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.12",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.13",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.14",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.15",
      "page": 27
    },
    {
      "level": "H5",
      "text": "4.16",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.1",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.2",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.3",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.4",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.5",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.6",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.7",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.8",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.9",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.10",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.11",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.12",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.13",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.14",
      "page": 27
    },
    {
      "level": "H5",
      "text": "5.15",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.1",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.2",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.3",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.4",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.5",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.6",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.7",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.8",
      "page": 27
    },
    {
      "level": "H5",
      "text": "6.9",
      "page": 27
    },
    {
      "level": "H5",
      "text": "7.1",
      "page": 27
    },
    {
      "level": "H5",
      "text": "8.1",
      "page": 27
    },
    {
      "level": "H5",
      "text": "8.2",
      "page": 27
    },
    {
      "level": "H5",
      "text": "8.3",
      "page": 27
    },
    {
      "level": "H5",
      "text": "9.1",
      "page": 27
    },
    {
      "level": "H5",
      "text": "9.2",
      "page": 27
    },
    {
      "level": "H5",
      "text": "9.3",
      "page": 27
    },
    {
      "level": "H5",
      "text": "LIST OF FIGURES",
      "page": 27
    },
    {
      "level": "H5",
      "text": "An attempt at an I-map for a nonpositive distribution P",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Different factor graphs for the same Markov network",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Energy functions for the Misconception example",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Alternative but equivalent energy functions",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Canonical energy function for the Misconception example",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of alternative deﬁnition of d-separation based on Markov networks",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Minimal I-map Bayesian networks for a nonchordal Markov network",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Different linear-chain graphical models",
      "page": 27
    },
    {
      "level": "H5",
      "text": "A chain graph K and its moralized version",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example for deﬁnition of c-separation in a chain graph",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of a network with a deterministic CPD",
      "page": 27
    },
    {
      "level": "H5",
      "text": "A slightly more complex example with deterministic CPDs",
      "page": 27
    },
    {
      "level": "H5",
      "text": "The Student example augmented with a Job variable",
      "page": 27
    },
    {
      "level": "H5",
      "text": "A tree-CPD for P (J | A, S, L)",
      "page": 27
    },
    {
      "level": "H5",
      "text": "The OneLetter example of a multiplexer dependency",
      "page": 27
    },
    {
      "level": "H5",
      "text": "tree-CPD for a rule-based CPD",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of removal of spurious edges",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Two reduced CPDs for the OneLetter example",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Decomposition of the noisy-or model for Letter",
      "page": 27
    },
    {
      "level": "H5",
      "text": "The behavior of the noisy-or model",
      "page": 27
    },
    {
      "level": "H5",
      "text": "The behavior of the sigmoid CPD",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of the multinomial logistic CPD",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Independence of causal inﬂuence",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Generalized linear model for a thermostat",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of encapsulated CPDs for a computer system model",
      "page": 27
    },
    {
      "level": "H5",
      "text": "A highly simpliﬁed DBN for monitoring a vehicle",
      "page": 27
    },
    {
      "level": "H5",
      "text": "HMM as a DBN",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Two classes of DBNs constructed from HMMs",
      "page": 27
    },
    {
      "level": "H5",
      "text": "A simple 4-state HMM",
      "page": 27
    },
    {
      "level": "H5",
      "text": "One possible world for the University example",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Plate model for a set of coin tosses sampled from a single coin",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Plate models and ground Bayesian networks for a simpliﬁed Student example",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Illustration of probabilistic interactions in the University domain",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Examples of dependency graphs",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Examples of 2-dimensional Gaussians",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of M- and I-projections into the family of Gaussian distributions",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Example of M- and I-projections for a discrete distribution",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Relationship between parameters, distributions, and expected sufficient statistics",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Network used to prove N P-hardness of exact inference",
      "page": 27
    },
    {
      "level": "H5",
      "text": "Computing P (D) by summing out the joint distribution",
      "page": 27
    },
    {
      "level": "H5",
      "text": "The ﬁrst transformation on the sum of ﬁgure 9.2",
      "page": 27
    },
    {
      "level": "H5",
      "text": "122",
      "page": 27
    },
    {
      "level": "H5",
      "text": "123",
      "page": 27
    },
    {
      "level": "H5",
      "text": "124",
      "page": 27
    },
    {
      "level": "H5",
      "text": "128",
      "page": 27
    },
    {
      "level": "H5",
      "text": "130",
      "page": 27
    },
    {
      "level": "H5",
      "text": "137",
      "page": 27
    },
    {
      "level": "H5",
      "text": "138",
      "page": 27
    },
    {
      "level": "H5",
      "text": "143",
      "page": 27
    },
    {
      "level": "H5",
      "text": "149",
      "page": 27
    },
    {
      "level": "H5",
      "text": "150",
      "page": 27
    },
    {
      "level": "H5",
      "text": "160",
      "page": 27
    },
    {
      "level": "H5",
      "text": "161",
      "page": 27
    },
    {
      "level": "H5",
      "text": "162",
      "page": 27
    },
    {
      "level": "H5",
      "text": "163",
      "page": 27
    },
    {
      "level": "H5",
      "text": "165",
      "page": 27
    },
    {
      "level": "H5",
      "text": "169",
      "page": 27
    },
    {
      "level": "H5",
      "text": "173",
      "page": 27
    },
    {
      "level": "H5",
      "text": "174",
      "page": 27
    },
    {
      "level": "H5",
      "text": "176",
      "page": 27
    },
    {
      "level": "H5",
      "text": "177",
      "page": 27
    },
    {
      "level": "H5",
      "text": "180",
      "page": 27
    },
    {
      "level": "H5",
      "text": "181",
      "page": 27
    },
    {
      "level": "H5",
      "text": "182",
      "page": 27
    },
    {
      "level": "H5",
      "text": "191",
      "page": 27
    },
    {
      "level": "H5",
      "text": "193",
      "page": 27
    },
    {
      "level": "H5",
      "text": "203",
      "page": 27
    },
    {
      "level": "H5",
      "text": "203",
      "page": 27
    },
    {
      "level": "H5",
      "text": "205",
      "page": 27
    },
    {
      "level": "H5",
      "text": "208",
      "page": 27
    },
    {
      "level": "H5",
      "text": "215",
      "page": 27
    },
    {
      "level": "H5",
      "text": "217",
      "page": 27
    },
    {
      "level": "H5",
      "text": "219",
      "page": 27
    },
    {
      "level": "H5",
      "text": "220",
      "page": 27
    },
    {
      "level": "H5",
      "text": "227",
      "page": 27
    },
    {
      "level": "H5",
      "text": "249",
      "page": 27
    },
    {
      "level": "H5",
      "text": "275",
      "page": 27
    },
    {
      "level": "H5",
      "text": "276",
      "page": 27
    },
    {
      "level": "H5",
      "text": "279",
      "page": 27
    },
    {
      "level": "H5",
      "text": "289",
      "page": 27
    },
    {
      "level": "H5",
      "text": "294",
      "page": 27
    },
    {
      "level": "H5",
      "text": "295",
      "page": 27
    },
    {
      "level": "H5",
      "text": "LIST OF FIGURES",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.4",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.5",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.6",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.7",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.8",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.9",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.10",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.11",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.12",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.13",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.14",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.15",
      "page": 28
    },
    {
      "level": "H5",
      "text": "9.16",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.1",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.2",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.3",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.4",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.5",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.6",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.7",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.8",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.9",
      "page": 28
    },
    {
      "level": "H5",
      "text": "10.10",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.1",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.2",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.3",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.4",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.5",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.6",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.7",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.8",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.9",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.10",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.11",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.12",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.13",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.14",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.15",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.16",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.17",
      "page": 28
    },
    {
      "level": "H5",
      "text": "11.18",
      "page": 28
    },
    {
      "level": "H5",
      "text": "The second transformation on the sum of ﬁgure 9.2",
      "page": 28
    },
    {
      "level": "H5",
      "text": "The third transformation on the sum of ﬁgure 9.2",
      "page": 28
    },
    {
      "level": "H5",
      "text": "The fourth transformation on the sum of ﬁgure 9.2",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Example of factor marginalization",
      "page": 28
    },
    {
      "level": "H5",
      "text": "The Extended-Student Bayesian network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Understanding intermediate factors in variable elimination",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Variable elimination as graph transformation in the Student example",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Induced graph and clique tree for the Student example",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Networks where conditioning performs unnecessary computation",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Induced graph for the Student example using both conditioning and elimination",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Different decompositions for a noisy-or CPD",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Example Bayesian network with rule-based structure",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Conditioning in a network with CSI",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Cluster tree for the VE execution in table 9.1",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Simpliﬁed clique tree T for the Extended Student network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Message propagations with different root cliques in the Student clique tree",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An abstract clique tree that is not chain-structured",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Two steps in a downward pass in the Student network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Final beliefs for the Misconception example",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example of factor division",
      "page": 28
    },
    {
      "level": "H5",
      "text": "A modiﬁed Student BN with an unambitious student",
      "page": 28
    },
    {
      "level": "H5",
      "text": "A clique tree for the modiﬁed Student BN of ﬁgure 10.8",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Example of clique tree construction algorithm",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example of a cluster graph versus a clique tree",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example run of loopy belief propagation",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Two examples of generalized cluster graph for an MRF",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example of a 4 × 4 two-dimensional grid network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example of generalized cluster graph for a 3 × 3 grid network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "A generalized cluster graph for the 3 × 3 grid when viewed as pairwise MRF",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Examples of generalized cluster graphs for network with potentials {A, B, C},",
      "page": 28
    },
    {
      "level": "H5",
      "text": "{B, C, D}, {B, D, F }, {B, E} and {D, E}",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Examples of generalized cluster graphs for networks with potentials {A, B, C},",
      "page": 28
    },
    {
      "level": "H5",
      "text": "{B, C, D}, and {A, C, D}",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example of simple region graph",
      "page": 28
    },
    {
      "level": "H5",
      "text": "The region graph corresponding to the Bethe cluster graph of ﬁgure 11.7a",
      "page": 28
    },
    {
      "level": "H5",
      "text": "The messages participating in different region graph computations",
      "page": 28
    },
    {
      "level": "H5",
      "text": "A cluster for a 4 × 4 grid network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Effect of different message factorizations on the beliefs in the receiving factor",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Example of propagation in cluster tree with factorized messages",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Markov network used to demonstrate approximate message passing",
      "page": 28
    },
    {
      "level": "H5",
      "text": "An example of a multimodal mean ﬁeld energy functional landscape",
      "page": 28
    },
    {
      "level": "H5",
      "text": "Two structures for variational approximation of a 4 × 4 grid network",
      "page": 28
    },
    {
      "level": "H5",
      "text": "A diamond network and three possible approximating structures",
      "page": 28
    },
    {
      "level": "H5",
      "text": "xxvii",
      "page": 28
    },
    {
      "level": "H5",
      "text": "295",
      "page": 28
    },
    {
      "level": "H5",
      "text": "295",
      "page": 28
    },
    {
      "level": "H5",
      "text": "295",
      "page": 28
    },
    {
      "level": "H5",
      "text": "297",
      "page": 28
    },
    {
      "level": "H5",
      "text": "300",
      "page": 28
    },
    {
      "level": "H5",
      "text": "303",
      "page": 28
    },
    {
      "level": "H5",
      "text": "308",
      "page": 28
    },
    {
      "level": "H5",
      "text": "309",
      "page": 28
    },
    {
      "level": "H5",
      "text": "321",
      "page": 28
    },
    {
      "level": "H5",
      "text": "323",
      "page": 28
    },
    {
      "level": "H5",
      "text": "326",
      "page": 28
    },
    {
      "level": "H5",
      "text": "329",
      "page": 28
    },
    {
      "level": "H5",
      "text": "334",
      "page": 28
    },
    {
      "level": "H5",
      "text": "346",
      "page": 28
    },
    {
      "level": "H5",
      "text": "349",
      "page": 28
    },
    {
      "level": "H5",
      "text": "350",
      "page": 28
    },
    {
      "level": "H5",
      "text": "352",
      "page": 28
    },
    {
      "level": "H5",
      "text": "356",
      "page": 28
    },
    {
      "level": "H5",
      "text": "362",
      "page": 28
    },
    {
      "level": "H5",
      "text": "365",
      "page": 28
    },
    {
      "level": "H5",
      "text": "373",
      "page": 28
    },
    {
      "level": "H5",
      "text": "373",
      "page": 28
    },
    {
      "level": "H5",
      "text": "375",
      "page": 28
    },
    {
      "level": "H5",
      "text": "391",
      "page": 28
    },
    {
      "level": "H5",
      "text": "392",
      "page": 28
    },
    {
      "level": "H5",
      "text": "393",
      "page": 28
    },
    {
      "level": "H5",
      "text": "398",
      "page": 28
    },
    {
      "level": "H5",
      "text": "399",
      "page": 28
    },
    {
      "level": "H5",
      "text": "405",
      "page": 28
    },
    {
      "level": "H5",
      "text": "406",
      "page": 28
    },
    {
      "level": "H5",
      "text": "407",
      "page": 28
    },
    {
      "level": "H5",
      "text": "420",
      "page": 28
    },
    {
      "level": "H5",
      "text": "421",
      "page": 28
    },
    {
      "level": "H5",
      "text": "425",
      "page": 28
    },
    {
      "level": "H5",
      "text": "430",
      "page": 28
    },
    {
      "level": "H5",
      "text": "431",
      "page": 28
    },
    {
      "level": "H5",
      "text": "433",
      "page": 28
    },
    {
      "level": "H5",
      "text": "438",
      "page": 28
    },
    {
      "level": "H5",
      "text": "456",
      "page": 28
    },
    {
      "level": "H5",
      "text": "457",
      "page": 28
    },
    {
      "level": "H5",
      "text": "462",
      "page": 28
    },
    {
      "level": "H5",
      "text": "xxviii",
      "page": 29
    },
    {
      "level": "H5",
      "text": "LIST OF FIGURES",
      "page": 29
    },
    {
      "level": "H5",
      "text": "11.19",
      "page": 29
    },
    {
      "level": "H5",
      "text": "11.20",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Simpliﬁcation of approximating structure in cluster mean ﬁeld",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Illustration of the variational bound − ln(x) ≥ −λx + ln(λ) + 1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.2",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.3",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.4",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.5",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.6",
      "page": 29
    },
    {
      "level": "H5",
      "text": "12.7",
      "page": 29
    },
    {
      "level": "H5",
      "text": "13.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "13.2",
      "page": 29
    },
    {
      "level": "H5",
      "text": "13.3",
      "page": 29
    },
    {
      "level": "H5",
      "text": "13.4",
      "page": 29
    },
    {
      "level": "H5",
      "text": "13.5",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.2",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.3",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.4",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.5",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.6",
      "page": 29
    },
    {
      "level": "H5",
      "text": "14.7",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.2",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.3",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.4",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.5",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.6",
      "page": 29
    },
    {
      "level": "H5",
      "text": "15.7",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The Student network Bstudent revisited",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The mutilated network Bstudent",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The Grasshopper Markov chain",
      "page": 29
    },
    {
      "level": "H5",
      "text": "A simple Markov chain",
      "page": 29
    },
    {
      "level": "H5",
      "text": "A Bayesian network with four students, two courses, and ﬁve grades",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Visualization of a Markov chain with low conductance",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Networks illustrating collapsed importance sampling",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Example of the max-marginalization factor operation for variable B",
      "page": 29
    },
    {
      "level": "H5",
      "text": "A network where a marginal MAP query requires exponential time",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The max-marginals for the Misconception example",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Two induced subgraphs derived from ﬁgure 11.3a",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Example graph construction for applying min-cut to the binary MAP problem",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Gaussian MRF illustrating convergence properties of Gaussian belief propagation",
      "page": 29
    },
    {
      "level": "H5",
      "text": "CLG network used to demonstrate hardness of inference",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Joint marginal distribution p(X1, X2) for a network as in ﬁgure 14.2",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Summing and collapsing a Gaussian mixture",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Example of unnormalizable potentials in a CLG clique tree",
      "page": 29
    },
    {
      "level": "H5",
      "text": "A simple CLG and possible clique trees with different correctness properties",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Different Gaussian approximation methods for a nonlinear dependency",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Clique tree for HMM",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Different clique trees for the Car DBN of ﬁgure 6.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Nonpersistent 2-TBN and different possible clique trees",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Performance of likelihood weighting over time",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Illustration of the particle ﬁltering algorithm",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Likelihood weighting and particle ﬁltering over time",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Three collapsing strategies for CLG DBNs, and their EP perspective",
      "page": 29
    },
    {
      "level": "H5",
      "text": "16.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The effect of ignoring hidden variables",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.1",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.2",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.3",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.4",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.5",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.6",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.7",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.8",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.9",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.10",
      "page": 29
    },
    {
      "level": "H5",
      "text": "17.11",
      "page": 29
    },
    {
      "level": "H5",
      "text": "A simple thumbtack tossing experiment",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The likelihood function for the sequence of tosses H, T, T, H, H",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Meta-network for IID samples of a random variable",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Examples of Beta distributions for different choices of hyperparameters",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The effect of the Beta prior on our posterior estimates",
      "page": 29
    },
    {
      "level": "H5",
      "text": "The effect of different priors on smoothing our parameter estimates",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Meta-network for IID samples from X → Y with global parameter independence",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Meta-network for IID samples from X → Y with local parameter independence",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Two plate models for the University example, with explicit parameter variables",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Example meta-network for a model with shared parameters",
      "page": 29
    },
    {
      "level": "H5",
      "text": "Independent and hierarchical priors",
      "page": 29
    },
    {
      "level": "H5",
      "text": "468",
      "page": 29
    },
    {
      "level": "H5",
      "text": "469",
      "page": 29
    },
    {
      "level": "H5",
      "text": "488",
      "page": 29
    },
    {
      "level": "H5",
      "text": "499",
      "page": 29
    },
    {
      "level": "H5",
      "text": "507",
      "page": 29
    },
    {
      "level": "H5",
      "text": "509",
      "page": 29
    },
    {
      "level": "H5",
      "text": "514",
      "page": 29
    },
    {
      "level": "H5",
      "text": "520",
      "page": 29
    },
    {
      "level": "H5",
      "text": "528",
      "page": 29
    },
    {
      "level": "H5",
      "text": "555",
      "page": 29
    },
    {
      "level": "H5",
      "text": "561",
      "page": 29
    },
    {
      "level": "H5",
      "text": "564",
      "page": 29
    },
    {
      "level": "H5",
      "text": "570",
      "page": 29
    },
    {
      "level": "H5",
      "text": "590",
      "page": 29
    },
    {
      "level": "H5",
      "text": "615",
      "page": 29
    },
    {
      "level": "H5",
      "text": "615",
      "page": 29
    },
    {
      "level": "H5",
      "text": "616",
      "page": 29
    },
    {
      "level": "H5",
      "text": "619",
      "page": 29
    },
    {
      "level": "H5",
      "text": "623",
      "page": 29
    },
    {
      "level": "H5",
      "text": "624",
      "page": 29
    },
    {
      "level": "H5",
      "text": "636",
      "page": 29
    },
    {
      "level": "H5",
      "text": "654",
      "page": 29
    },
    {
      "level": "H5",
      "text": "659",
      "page": 29
    },
    {
      "level": "H5",
      "text": "660",
      "page": 29
    },
    {
      "level": "H5",
      "text": "667",
      "page": 29
    },
    {
      "level": "H5",
      "text": "669",
      "page": 29
    },
    {
      "level": "H5",
      "text": "670",
      "page": 29
    },
    {
      "level": "H5",
      "text": "687",
      "page": 29
    },
    {
      "level": "H5",
      "text": "714",
      "page": 29
    },
    {
      "level": "H5",
      "text": "718",
      "page": 29
    },
    {
      "level": "H5",
      "text": "718",
      "page": 29
    },
    {
      "level": "H5",
      "text": "734",
      "page": 29
    },
    {
      "level": "H5",
      "text": "736",
      "page": 29
    },
    {
      "level": "H5",
      "text": "741",
      "page": 29
    },
    {
      "level": "H5",
      "text": "742",
      "page": 29
    },
    {
      "level": "H5",
      "text": "743",
      "page": 29
    },
    {
      "level": "H5",
      "text": "746",
      "page": 29
    },
    {
      "level": "H5",
      "text": "758",
      "page": 29
    },
    {
      "level": "H5",
      "text": "763",
      "page": 29
    },
    {
      "level": "H5",
      "text": "765",
      "page": 29
    },
    {
      "level": "H5",
      "text": "LIST OF FIGURES",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.1",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.2",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.3",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.4",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.5",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.6",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.7",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Marginal training likelihood versus expected likelihood on underlying distribution",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Maximal likelihood score versus marginal likelihood for the data (cid:104)H, T, T, H, H(cid:105).",
      "page": 30
    },
    {
      "level": "H5",
      "text": "The effect of correlation on the Bayesian score",
      "page": 30
    },
    {
      "level": "H5",
      "text": "The Bayesian scores of three structures for the ICU-Alarm domain",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Example of a search problem requiring edge deletion",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Example of a search problem requiring edge reversal",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Performance of structure and parameter learning for instances from ICU-Alarm",
      "page": 30
    },
    {
      "level": "H5",
      "text": "network",
      "page": 30
    },
    {
      "level": "H5",
      "text": "MCMC structure search using 500 instances from ICU-Alarm network",
      "page": 30
    },
    {
      "level": "H5",
      "text": "MCMC structure search using 1,000 instances from ICU-Alarm network",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.8",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.9",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.10 MCMC order search using 1,000 instances from ICU-Alarm network",
      "page": 30
    },
    {
      "level": "H5",
      "text": "18.11",
      "page": 30
    },
    {
      "level": "H5",
      "text": "A simple module network",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.1",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.2",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.3",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.4",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.5",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.6",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.7",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.8",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.9",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.10",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.11",
      "page": 30
    },
    {
      "level": "H5",
      "text": "19.12",
      "page": 30
    },
    {
      "level": "H5",
      "text": "20.1",
      "page": 30
    },
    {
      "level": "H5",
      "text": "20.2",
      "page": 30
    },
    {
      "level": "H5",
      "text": "20.3",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.1",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.2",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.3",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.4",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.5",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.6",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.7",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.8",
      "page": 30
    },
    {
      "level": "H5",
      "text": "21.9",
      "page": 30
    },
    {
      "level": "H5",
      "text": "22.1",
      "page": 30
    },
    {
      "level": "H5",
      "text": "22.2",
      "page": 30
    },
    {
      "level": "H5",
      "text": "23.1",
      "page": 30
    },
    {
      "level": "H5",
      "text": "23.2",
      "page": 30
    },
    {
      "level": "H5",
      "text": "23.3",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Observation models in two variants of the thumbtack example",
      "page": 30
    },
    {
      "level": "H5",
      "text": "An example satisfying MAR but not MCAR",
      "page": 30
    },
    {
      "level": "H5",
      "text": "A visualization of a multimodal likelihood function with incomplete data",
      "page": 30
    },
    {
      "level": "H5",
      "text": "The meta-network for parameter estimation for X → Y",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Contour plots for the likelihood function for X → Y",
      "page": 30
    },
    {
      "level": "H5",
      "text": "A simple network used to illustrate learning algorithms for missing data",
      "page": 30
    },
    {
      "level": "H5",
      "text": "The naive Bayes clustering model",
      "page": 30
    },
    {
      "level": "H5",
      "text": "The hill-climbing process performed by the EM algorithm",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Plate model for Bayesian clustering",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Nondecomposability of structure scores in the case of missing data",
      "page": 30
    },
    {
      "level": "H5",
      "text": "An example of a network with a hierarchy of hidden variables",
      "page": 30
    },
    {
      "level": "H5",
      "text": "An example of a network with overlapping hidden variables",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Log-likelihood surface for the Markov network A—B—C",
      "page": 30
    },
    {
      "level": "H5",
      "text": "A highly connected CRF that allows simple inference when conditioned",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Laplacian distribution (β = 1) and Gaussian distribution (σ2 = 1)",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Mutilated Student networks representing interventions",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Causal network for Simpson’s paradox",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Models where P (Y | do(X)) is identiﬁable",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Models where P (Y | do(X)) is not identiﬁable",
      "page": 30
    },
    {
      "level": "H5",
      "text": "A simple functional causal model for a clinical trial",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Twinned counterfactual network with an intervention",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Models corresponding to the equivalence class of the Student network",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Example PAG and members of its equivalence class",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Learned causal network for exercise 21.12",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Example curve for the utility of money",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Utility curve and its consequences to an agent’s attitude toward risk",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Decision trees for the Entrepreneur example",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Inﬂuence diagram IF for the basic Entrepreneur example",
      "page": 30
    },
    {
      "level": "H5",
      "text": "Inﬂuence diagram IF,C for Entrepreneur example with market survey",
      "page": 30
    },
    {
      "level": "H5",
      "text": "xxix",
      "page": 30
    },
    {
      "level": "H5",
      "text": "796",
      "page": 30
    },
    {
      "level": "H5",
      "text": "797",
      "page": 30
    },
    {
      "level": "H5",
      "text": "801",
      "page": 30
    },
    {
      "level": "H5",
      "text": "802",
      "page": 30
    },
    {
      "level": "H5",
      "text": "813",
      "page": 30
    },
    {
      "level": "H5",
      "text": "814",
      "page": 30
    },
    {
      "level": "H5",
      "text": "820",
      "page": 30
    },
    {
      "level": "H5",
      "text": "830",
      "page": 30
    },
    {
      "level": "H5",
      "text": "831",
      "page": 30
    },
    {
      "level": "H5",
      "text": "833",
      "page": 30
    },
    {
      "level": "H5",
      "text": "847",
      "page": 30
    },
    {
      "level": "H5",
      "text": "851",
      "page": 30
    },
    {
      "level": "H5",
      "text": "853",
      "page": 30
    },
    {
      "level": "H5",
      "text": "857",
      "page": 30
    },
    {
      "level": "H5",
      "text": "858",
      "page": 30
    },
    {
      "level": "H5",
      "text": "858",
      "page": 30
    },
    {
      "level": "H5",
      "text": "864",
      "page": 30
    },
    {
      "level": "H5",
      "text": "875",
      "page": 30
    },
    {
      "level": "H5",
      "text": "882",
      "page": 30
    },
    {
      "level": "H5",
      "text": "902",
      "page": 30
    },
    {
      "level": "H5",
      "text": "918",
      "page": 30
    },
    {
      "level": "H5",
      "text": "931",
      "page": 30
    },
    {
      "level": "H5",
      "text": "931",
      "page": 30
    },
    {
      "level": "H5",
      "text": "945",
      "page": 30
    },
    {
      "level": "H5",
      "text": "952",
      "page": 30
    },
    {
      "level": "H5",
      "text": "959",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1015",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1016",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1025",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1025",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1030",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1036",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1043",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1050",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1057",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1066",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1067",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1086",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1089",
      "page": 30
    },
    {
      "level": "H5",
      "text": "1091",
      "page": 30
    },
    {
      "level": "H5",
      "text": "xxx",
      "page": 31
    },
    {
      "level": "H5",
      "text": "LIST OF FIGURES",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Decision tree for the inﬂuence diagram IF,C in the Entrepreneur example",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Iterated optimization versus variable elimination",
      "page": 31
    },
    {
      "level": "H5",
      "text": "An inﬂuence diagram with multiple utility variables",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Inﬂuence diagrams, augmented to test for s-reachability",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Inﬂuence diagrams and their relevance graphs",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Clique tree for the imperfect-recall inﬂuence diagram of ﬁgure 23.5.",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.4",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.5",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.6",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.7",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.8",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.9",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.10 More complex inﬂuence diagram IS for the Student scenario",
      "page": 31
    },
    {
      "level": "H5",
      "text": "23.11",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Example for computing value of information using an inﬂuence diagram",
      "page": 31
    },
    {
      "level": "H5",
      "text": "A.1",
      "page": 31
    },
    {
      "level": "H5",
      "text": "A.2",
      "page": 31
    },
    {
      "level": "H5",
      "text": "A.3",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Illustration of asymptotic complexity",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Illustration of line search with Brent’s method",
      "page": 31
    },
    {
      "level": "H5",
      "text": "Two examples of the convergence problem with line search",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1096",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1099",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1101",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1112",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1114",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1116",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1120",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1123",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1149",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1165",
      "page": 31
    },
    {
      "level": "H5",
      "text": "1166",
      "page": 31
    },
    {
      "level": "H2",
      "text": "List of Algorithms",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Algorithm for ﬁnding nodes reachable from X given Z via active trails",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Procedure to build a minimal I-map given an ordering",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Recovering the undirected skeleton for a distribution P that has a P-map",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Finding the class PDAG characterizing the P-map of a distribution P",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Computing d-separation in the presence of deterministic CPDs",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Computing d-separation in the presence of context-speciﬁc CPDs",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Sum-product variable elimination algorithm",
      "page": 32
    },
    {
      "level": "H5",
      "text": "3.1",
      "page": 32
    },
    {
      "level": "H5",
      "text": "3.2",
      "page": 32
    },
    {
      "level": "H5",
      "text": "3.3",
      "page": 32
    },
    {
      "level": "H5",
      "text": "3.4 Marking immoralities in the construction of a perfect map",
      "page": 32
    },
    {
      "level": "H5",
      "text": "3.5",
      "page": 32
    },
    {
      "level": "H5",
      "text": "5.1",
      "page": 32
    },
    {
      "level": "H5",
      "text": "5.2",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.1",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.2 Using Sum-Product-VE for computing conditional probabilities",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.3 Maximum cardinality search for constructing an elimination ordering",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.4 Greedy search for constructing an elimination ordering",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Conditioning algorithm",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.5",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Rule splitting algorithm",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.6",
      "page": 32
    },
    {
      "level": "H5",
      "text": "9.7",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Sum-product variable elimination for sets of rules",
      "page": 32
    },
    {
      "level": "H5",
      "text": "10.1 Upward pass of variable elimination in clique tree",
      "page": 32
    },
    {
      "level": "H5",
      "text": "10.2 Calibration using sum-product message passing in a clique tree",
      "page": 32
    },
    {
      "level": "H5",
      "text": "10.3 Calibration using belief propagation in clique tree",
      "page": 32
    },
    {
      "level": "H5",
      "text": "10.4 Out-of-clique inference in clique tree",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Calibration using sum-product belief propagation in a cluster graph",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.1",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.2 Convergent message passing for Bethe cluster graph with convex counting",
      "page": 32
    },
    {
      "level": "H5",
      "text": "numbers",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Projecting a factor set to produce a set of marginals over a given set of scopes",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.3 Algorithm to construct a saturated region graph",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.4",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.5 Modiﬁed version of BU-Message that incorporates message projection",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.6 Message passing step in the expectation propagation algorithm",
      "page": 32
    },
    {
      "level": "H5",
      "text": "11.7 The Mean-Field approximation algorithm",
      "page": 32
    },
    {
      "level": "H5",
      "text": "12.1",
      "page": 32
    },
    {
      "level": "H5",
      "text": "Forward Sampling in a Bayesian network",
      "page": 32
    },
    {
      "level": "H5",
      "text": "12.2 Likelihood-weighted particle generation",
      "page": 32
    },
    {
      "level": "H5",
      "text": "12.3 Likelihood weighting with a data-dependent stopping rule",
      "page": 32
    },
    {
      "level": "H5",
      "text": "12.4 Generating a Gibbs chain trajectory",
      "page": 32
    },
    {
      "level": "H5",
      "text": "12.5 Generating a Markov chain trajectory",
      "page": 32
    },
    {
      "level": "H5",
      "text": "13.1 Variable elimination algorithm for MAP",
      "page": 32
    },
    {
      "level": "H5",
      "text": "160",
      "page": 32
    },
    {
      "level": "H5",
      "text": "173",
      "page": 32
    },
    {
      "level": "H5",
      "text": "298",
      "page": 32
    },
    {
      "level": "H5",
      "text": "304",
      "page": 32
    },
    {
      "level": "H5",
      "text": "312",
      "page": 32
    },
    {
      "level": "H5",
      "text": "314",
      "page": 32
    },
    {
      "level": "H5",
      "text": "317",
      "page": 32
    },
    {
      "level": "H5",
      "text": "332",
      "page": 32
    },
    {
      "level": "H5",
      "text": "333",
      "page": 32
    },
    {
      "level": "H5",
      "text": "353",
      "page": 32
    },
    {
      "level": "H5",
      "text": "357",
      "page": 32
    },
    {
      "level": "H5",
      "text": "367",
      "page": 32
    },
    {
      "level": "H5",
      "text": "371",
      "page": 32
    },
    {
      "level": "H5",
      "text": "397",
      "page": 32
    },
    {
      "level": "H5",
      "text": "418",
      "page": 32
    },
    {
      "level": "H5",
      "text": "423",
      "page": 32
    },
    {
      "level": "H5",
      "text": "434",
      "page": 32
    },
    {
      "level": "H5",
      "text": "441",
      "page": 32
    },
    {
      "level": "H5",
      "text": "443",
      "page": 32
    },
    {
      "level": "H5",
      "text": "455",
      "page": 32
    },
    {
      "level": "H5",
      "text": "489",
      "page": 32
    },
    {
      "level": "H5",
      "text": "493",
      "page": 32
    },
    {
      "level": "H5",
      "text": "502",
      "page": 32
    },
    {
      "level": "H5",
      "text": "506",
      "page": 32
    },
    {
      "level": "H5",
      "text": "509",
      "page": 32
    },
    {
      "level": "H5",
      "text": "557",
      "page": 32
    },
    {
      "level": "H5",
      "text": "xxxii",
      "page": 33
    },
    {
      "level": "H5",
      "text": "LIST OF ALGORITHMS",
      "page": 33
    },
    {
      "level": "H5",
      "text": "13.2 Max-product message computation for MAP",
      "page": 33
    },
    {
      "level": "H5",
      "text": "13.3 Calibration using max-product BP in a Bethe-structured cluster graph",
      "page": 33
    },
    {
      "level": "H5",
      "text": "13.4 Graph-cut algorithm for MAP in pairwise binary MRFs with submodular",
      "page": 33
    },
    {
      "level": "H5",
      "text": "potentials",
      "page": 33
    },
    {
      "level": "H5",
      "text": "13.5 Alpha-expansion algorithm",
      "page": 33
    },
    {
      "level": "H5",
      "text": "13.6 Efficient min-sum message passing for untruncated 1-norm energies",
      "page": 33
    },
    {
      "level": "H5",
      "text": "Expectation propagation message passing for CLG networks",
      "page": 33
    },
    {
      "level": "H5",
      "text": "14.1",
      "page": 33
    },
    {
      "level": "H5",
      "text": "15.1",
      "page": 33
    },
    {
      "level": "H5",
      "text": "Filtering in a DBN using a template clique tree",
      "page": 33
    },
    {
      "level": "H5",
      "text": "15.2 Likelihood-weighted particle generation for a 2-TBN",
      "page": 33
    },
    {
      "level": "H5",
      "text": "15.3 Likelihood weighting for ﬁltering in DBNs",
      "page": 33
    },
    {
      "level": "H5",
      "text": "15.4 Particle ﬁltering for DBNs",
      "page": 33
    },
    {
      "level": "H5",
      "text": "18.1 Data perturbation search",
      "page": 33
    },
    {
      "level": "H5",
      "text": "19.1 Computing the gradient in a network with table-CPDs",
      "page": 33
    },
    {
      "level": "H5",
      "text": "19.2 Expectation-maximization algorithm for BN with table-CPDs",
      "page": 33
    },
    {
      "level": "H5",
      "text": "19.3 The structural EM algorithm for structure learning",
      "page": 33
    },
    {
      "level": "H5",
      "text": "19.4 The incremental EM algorithm for network with table-CPDs",
      "page": 33
    },
    {
      "level": "H5",
      "text": "19.5 Proposal distribution for collapsed Metropolis-Hastings over data completions",
      "page": 33
    },
    {
      "level": "H5",
      "text": "19.6 Proposal distribution over partitions in the Dirichlet process priof",
      "page": 33
    },
    {
      "level": "H5",
      "text": "20.1 Greedy score-based structure search algorithm for log-linear models",
      "page": 33
    },
    {
      "level": "H5",
      "text": "23.1 Finding the MEU strategy in a decision tree",
      "page": 33
    },
    {
      "level": "H5",
      "text": "23.2 Generalized variable elimination for joint factors in inﬂuence diagrams",
      "page": 33
    },
    {
      "level": "H5",
      "text": "23.3 Iterated optimization for inﬂuence diagrams with acyclic relevance graphs",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.1",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.2 Maximum weight spanning tree in an undirected graph",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.3 Recursive algorithm for computing Fibonacci numbers",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.4 Dynamic programming algorithm for computing Fibonacci numbers",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.5 Greedy local search algorithm with search operators",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.6",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.7",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.8 Greedy hill-climbing search with random restarts",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.9 Branch and bound algorithm",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.10 Simple gradient ascent algorithm",
      "page": 33
    },
    {
      "level": "H5",
      "text": "A.11 Conjugate gradient ascent",
      "page": 33
    },
    {
      "level": "H5",
      "text": "Local search with tabu list",
      "page": 33
    },
    {
      "level": "H5",
      "text": "Beam search",
      "page": 33
    },
    {
      "level": "H5",
      "text": "Topological sort of a graph",
      "page": 33
    },
    {
      "level": "H5",
      "text": "562",
      "page": 33
    },
    {
      "level": "H5",
      "text": "573",
      "page": 33
    },
    {
      "level": "H5",
      "text": "591",
      "page": 33
    },
    {
      "level": "H5",
      "text": "593",
      "page": 33
    },
    {
      "level": "H5",
      "text": "603",
      "page": 33
    },
    {
      "level": "H5",
      "text": "622",
      "page": 33
    },
    {
      "level": "H5",
      "text": "657",
      "page": 33
    },
    {
      "level": "H5",
      "text": "666",
      "page": 33
    },
    {
      "level": "H5",
      "text": "666",
      "page": 33
    },
    {
      "level": "H5",
      "text": "670",
      "page": 33
    },
    {
      "level": "H5",
      "text": "817",
      "page": 33
    },
    {
      "level": "H5",
      "text": "867",
      "page": 33
    },
    {
      "level": "H5",
      "text": "873",
      "page": 33
    },
    {
      "level": "H5",
      "text": "922",
      "page": 33
    },
    {
      "level": "H5",
      "text": "939",
      "page": 33
    },
    {
      "level": "H5",
      "text": "941",
      "page": 33
    },
    {
      "level": "H5",
      "text": "942",
      "page": 33
    },
    {
      "level": "H5",
      "text": "986",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1088",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1105",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1116",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1146",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1147",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1150",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1150",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1155",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1157",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1158",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1159",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1161",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1164",
      "page": 33
    },
    {
      "level": "H5",
      "text": "1167",
      "page": 33
    },
    {
      "level": "H2",
      "text": "List of Boxes",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 3.A Concept: The Naive Bayes Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 3.B Case Study: The Genetics Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 3.B.1 Modeling Genetic Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 3.C Skill: Knowledge Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 3.D Case Study: Medical Diagnosis Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 4.A Concept: Pairwise Markov Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 4.A.1 A pairwise Markov network (MRF) structured as a grid. . . . . . . . . . . . . . . . . . . . . . 110",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 4.B Case Study: Markov Networks for Computer Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 4.B.1 Two examples of image segmentation results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 4.C Concept: Ising Models and Boltzmann Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 4.D Concept: Metric MRFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 4.E Case Study: CRFs for Text Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 4.E.1 Two models for text analysis based on a linear chain CRF . . . . . . . . . . . . . . . . . . . 147",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 5.A Case Study: Context-Speciﬁcity in Diagnostic Networks . . . . . . . . . . . . . . . . . . . . . . . . . . 166",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 5.A.1 Context-speciﬁc independencies for diagnostic networks. . . . . . . . . . . . . . . . . . . . 167",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 5.B Concept: Multinets and Similarity Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 5.C Concept: BN2O Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 5.C.1 A two-layer noisy-or network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 5.D Case Study: Noisy Rule Models for Medical Diagnosis . . . . . . . . . . . . . . . . . . . . . . . . . . . 183",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 5.E Case Study: Robot Motion and Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 5.E.1 Probabilistic model for robot localization track. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 6.A Case Study: HMMs and Phylo-HMMs for Gene Finding . . . . . . . . . . . . . . . . . . . . . . . . . . 206",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 6.B Case Study: HMMs for Speech Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 6.B.1 A phoneme-level HMM for a fairly complex phoneme. . . . . . . . . . . . . . . . . . . . . . 210",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 6.C Case Study: Collective Classiﬁcation of Web Pages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 6.D Case Study: Object Uncertainty and Citation Matching . . . . . . . . . . . . . . . . . . . . . . . . . . 238",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 6.D.1 Two template models for citation-matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 9.A Concept: The Network Polynomial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 9.B Concept: Polytrees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Box 9.C Case Study: Variable Elimination Orderings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315",
      "page": 34
    },
    {
      "level": "H5",
      "text": "Figure 9.C.1 Comparison of algorithms for selecting variable elimination ordering. . . . . . . . . 316",
      "page": 34
    },
    {
      "level": "H5",
      "text": "xxxiv",
      "page": 35
    },
    {
      "level": "H5",
      "text": "List of Boxes",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Algorithm 10.A.1 Efficient implementation of a factor product operation.",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 9.D Case Study: Inference with Local Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 10.A Skill: Efficient Implementation of Factor Manipulation Algorithms . . . . . . . . . . . . . . . . 358",
      "page": 35
    },
    {
      "level": "H5",
      "text": ". . . . . . . . . . . . . . . 359",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 11.A Case Study: Turbocodes and loopy belief propagation . . . . . . . . . . . . . . . . . . . . . . . . . . . 393",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 11.A.1 Two examples of codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 11.B Skill: Making loopy belief propagation work in practice . . . . . . . . . . . . . . . . . . . . . . . . . . 407",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 11.C Case Study: BP in practice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 11.C.1 Example of behavior of BP in practice on an 11 × 11 Ising grid. . . . . . . . . . . . . 410",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 12.A Skill: Sampling from a Discrete Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 12.B Skill: MCMC in Practice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 522",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 12.C Case Study: The bugs System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 12.C.1 Example of bugs model speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 12.D Concept: Correspondence and Data Association . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 532",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 12.D.1 Results of a correspondence algorithm for 3D human body scans . . . . . . . . . . 535",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 13.A Concept: Tree-Reweighted Belief Propagation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 13.B Case Study: Energy Minimization in Computer Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . 593",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 13.B.1 MAP inference for stereo reconstruction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 15.A Case Study: Tracking, Localization, and Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 15.A.1",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Illustration of Kalman ﬁltering for tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 679",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 15.A.2 Sample trajectory of particle ﬁltering for robot localization . . . . . . . . . . . . . . . . . 681",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 15.A.3 Kalman ﬁlters for the SLAM problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 682",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 15.A.4 Collapsed particle ﬁltering for SLAM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 684",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 16.A Skill: Design and Evaluation of Learning Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 705",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Algorithm 16.A.1 Algorithms for holdout and cross-validation tests. . . . . . . . . . . . . . . . . . . . . . . 707",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 16.B Concept: PAC-bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 708",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 17.A Concept: Naive Bayes Classiﬁer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 727",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 17.B Concept: Nonparametric Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 730",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 17.C Case Study: Learning the ICU-Alarm Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 749",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 17.C.1 The ICU-Alarm Bayesian network. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 750",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 17.C.2 Learning curve for parameter estimation for the ICU-Alarm network . . . . . . . . 751",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 17.D Concept: Representation Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 752",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 17.E Concept: Bag-of-Word Models for Text Classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 766",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 17.E.1 Different plate models for text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 768",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 18.A Skill: Practical Collection of Sufficient Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 819",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 18.B Concept: Dependency Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 822",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 18.C Case Study: Bayesian Networks for Collaborative Filtering . . . . . . . . . . . . . . . . . . . . . . . 823",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 18.C.1 Learned Bayesian network for collaborative ﬁltering. . . . . . . . . . . . . . . . . . . . . . . 823",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 19.A Case Study: Discovering User Clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 877",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 19.A.1 Application of Bayesian clustering to collaborative ﬁltering. . . . . . . . . . . . . . . . . 878",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 19.B Case Study: EM in Practice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 885",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 19.B.1 Convergence of EM run on the ICU Alarm network. . . . . . . . . . . . . . . . . . . . . . . . 885",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 19.B.2 Local maxima in likelihood surface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 886",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 19.C Skill: Practical Considerations in Parameter Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 888",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Box 19.D Case Study: EM for Robot Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 892",
      "page": 35
    },
    {
      "level": "H5",
      "text": "Figure 19.D.1 Sample results from EM-based 3D plane mapping . . . . . . . . . . . . . . . . . . . . . . . . 893",
      "page": 35
    },
    {
      "level": "H5",
      "text": "List of Boxes",
      "page": 36
    },
    {
      "level": "H5",
      "text": "xxxv",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 19.E Skill: Sampling from a Dirichlet distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 900",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 19.F Concept: Laplace Approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 909",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 19.G Case Study: Evaluating Structure Scores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 915",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Figure 19.G.1 Evaluation of structure scores for a naive Bayes clustering model . . . . . . . . . . . 916",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 20.A Concept: Generative and Discriminative Models for Sequence Labeling . . . . . . . . . . . 952",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Figure 20.A.1 Different models for sequence labeling: HMM, MEMM, and CRF . . . . . . . . . . . 953",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 20.B Case Study: CRFs for Protein Structure Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 968",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 21.A Case Study: Identifying the Effect of Smoking on Cancer . . . . . . . . . . . . . . . . . . . . . . . 1021",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Figure 21.A.1 Three candidate models for smoking and cancer. . . . . . . . . . . . . . . . . . . . . . . . . 1022",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Figure 21.A.2 Determining causality between smoking and cancer. . . . . . . . . . . . . . . . . . . . . . 1023",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 21.B Case Study: The Effect of Cholestyramine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1033",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 21.C Case Study: Persistence Networks for Diagnosis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1037",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 21.D Case Study: Learning Cellular Networks from Intervention Data . . . . . . . . . . . . . . . . . 1046",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 22.A Case Study: Prenatal Diagnosis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1079",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Figure 22.A.1 Typical utility function decomposition for prenatal diagnosis . . . . . . . . . . . . . 1080",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 22.B Case Study: Utility Elicitation in Medical Diagnosis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1080",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 23.A Case Study: Decision Making for Prenatal Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1094",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 23.B Case Study: Coordination Graphs for Robot Soccer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1117",
      "page": 36
    },
    {
      "level": "H5",
      "text": "Box 23.C Case Study: Decision Making for Troubleshooting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1125",
      "page": 36
    },
    {
      "level": "H4",
      "text": "1.1 Motivation",
      "page": 38
    },
    {
      "level": "H5",
      "text": "Most tasks require a person or an automated system to reason: to take the available information",
      "page": 38
    },
    {
      "level": "H5",
      "text": "and reach conclusions, both about what might be true in the world and about how to act.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "For example, a doctor needs to take information about a patient — his symptoms, test results,",
      "page": 38
    },
    {
      "level": "H5",
      "text": "personal characteristics (gender, weight) — and reach conclusions about what diseases he may",
      "page": 38
    },
    {
      "level": "H5",
      "text": "have and what course of treatment to undertake. A mobile robot needs to synthesize data from",
      "page": 38
    },
    {
      "level": "H5",
      "text": "its sonars, cameras, and other sensors to conclude where in the environment it is and how to",
      "page": 38
    },
    {
      "level": "H5",
      "text": "move so as to reach its goal without hitting anything. A speech-recognition system needs to",
      "page": 38
    },
    {
      "level": "H5",
      "text": "take a noisy acoustic signal and infer the words spoken that gave rise to it.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "In this book, we describe a general framework that can be used to allow a computer system",
      "page": 38
    },
    {
      "level": "H5",
      "text": "In principle, one could write a special-purpose computer",
      "page": 38
    },
    {
      "level": "H5",
      "text": "to answer questions of this type.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "program for every domain one encounters and every type of question that one may wish to",
      "page": 38
    },
    {
      "level": "H5",
      "text": "answer. The resulting system, although possibly quite successful at its particular task, is often",
      "page": 38
    },
    {
      "level": "H5",
      "text": "very brittle:",
      "page": 38
    },
    {
      "level": "H5",
      "text": "If our application changes, signiﬁcant changes may be required to the program.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "Moreover, this general approach is quite limiting, in that it is hard to extract lessons from one",
      "page": 38
    },
    {
      "level": "H5",
      "text": "successful solution and apply it to one which is very different.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "declarative",
      "page": 38
    },
    {
      "level": "H5",
      "text": "representation",
      "page": 38
    },
    {
      "level": "H5",
      "text": "model",
      "page": 38
    },
    {
      "level": "H5",
      "text": "We focus on a different approach, based on the concept of a declarative representation.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "this approach, we construct, within the computer, a model of the system about which we would",
      "page": 38
    },
    {
      "level": "H5",
      "text": "like to reason. This model encodes our knowledge of how the system works in a computer-",
      "page": 38
    },
    {
      "level": "H5",
      "text": "readable form. This representation can be manipulated by various algorithms that can answer",
      "page": 38
    },
    {
      "level": "H5",
      "text": "questions based on the model. For example, a model for medical diagnosis might represent our",
      "page": 38
    },
    {
      "level": "H5",
      "text": "knowledge about different diseases and how they relate to a variety of symptoms and test results.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "A reasoning algorithm can take this model, as well as observations relating to a particular patient,",
      "page": 38
    },
    {
      "level": "H5",
      "text": "and answer questions relating to the patient’s diagnosis. The key property of a declarative",
      "page": 38
    },
    {
      "level": "H2",
      "text": "(cid:17) representation is the separation of knowledge and reasoning. The representation has its",
      "page": 38
    },
    {
      "level": "H5",
      "text": "own clear semantics, separate from the algorithms that one can apply to it. Thus, we can",
      "page": 38
    },
    {
      "level": "H5",
      "text": "develop a general suite of algorithms that apply any model within a broad class, whether",
      "page": 38
    },
    {
      "level": "H5",
      "text": "in the domain of medical diagnosis or speech recognition. Conversely, we can improve",
      "page": 38
    },
    {
      "level": "H5",
      "text": "our model for a speciﬁc application domain without having to modify our reasoning",
      "page": 38
    },
    {
      "level": "H5",
      "text": "algorithms constantly.",
      "page": 38
    },
    {
      "level": "H5",
      "text": "Declarative representations, or model-based methods, are a fundamental component in many",
      "page": 38
    },
    {
      "level": "H5",
      "text": "ﬁelds, and models come in many ﬂavors. Our focus in this book is on models for complex sys-",
      "page": 38
    },
    {
      "level": "H5",
      "text": "uncertainty",
      "page": 39
    },
    {
      "level": "H5",
      "text": "Chapter 1.",
      "page": 39
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 39
    },
    {
      "level": "H5",
      "text": "tems that involve a signiﬁcant amount of uncertainty. Uncertainty appears to be an inescapable",
      "page": 39
    },
    {
      "level": "H5",
      "text": "aspect of most real-world applications.",
      "page": 39
    },
    {
      "level": "H5",
      "text": "It is a consequence of several factors. We are often",
      "page": 39
    },
    {
      "level": "H5",
      "text": "uncertain about the true state of the system because our observations about it are partial: only",
      "page": 39
    },
    {
      "level": "H5",
      "text": "some aspects of the world are observed; for example, the patient’s true disease is often not",
      "page": 39
    },
    {
      "level": "H5",
      "text": "directly observable, and his future prognosis is never observed. Our observations are also noisy",
      "page": 39
    },
    {
      "level": "H5",
      "text": "— even those aspects that are observed are often observed with some error. The true state of",
      "page": 39
    },
    {
      "level": "H5",
      "text": "the world is rarely determined with certainty by our limited observations, as most relationships",
      "page": 39
    },
    {
      "level": "H5",
      "text": "are simply not deterministic, at least relative to our ability to model them. For example, there",
      "page": 39
    },
    {
      "level": "H5",
      "text": "are few (if any) diseases where we have a clear, universally true relationship between the disease",
      "page": 39
    },
    {
      "level": "H5",
      "text": "and its symptoms, and even fewer such relationships between the disease and its prognosis.",
      "page": 39
    },
    {
      "level": "H5",
      "text": "Indeed, while it is not clear whether the universe (quantum mechanics aside) is deterministic",
      "page": 39
    },
    {
      "level": "H5",
      "text": "when modeled at a sufficiently ﬁne level of granularity, it is quite clear that it is not determin-",
      "page": 39
    },
    {
      "level": "H5",
      "text": "istic relative to our current understanding of it. To summarize, uncertainty arises because of",
      "page": 39
    },
    {
      "level": "H5",
      "text": "limitations in our ability to observe the world, limitations in our ability to model it, and possibly",
      "page": 39
    },
    {
      "level": "H5",
      "text": "even because of innate nondeterminism.",
      "page": 39
    },
    {
      "level": "H5",
      "text": "probability theory",
      "page": 39
    },
    {
      "level": "H5",
      "text": "Because of this ubiquitous and fundamental uncertainty about the true state of world, we",
      "page": 39
    },
    {
      "level": "H5",
      "text": "need to allow our reasoning system to consider different possibilities. One approach is simply",
      "page": 39
    },
    {
      "level": "H5",
      "text": "to consider any state of the world that is possible. Unfortunately, it is only rarely the case",
      "page": 39
    },
    {
      "level": "H5",
      "text": "that we can completely eliminate a state as being impossible given our observations.",
      "page": 39
    },
    {
      "level": "H5",
      "text": "In our",
      "page": 39
    },
    {
      "level": "H5",
      "text": "medical diagnosis example, there is usually a huge number of diseases that are possible given a",
      "page": 39
    },
    {
      "level": "H5",
      "text": "particular set of observations. Most of them, however, are highly unlikely. If we simply list all of",
      "page": 39
    },
    {
      "level": "H5",
      "text": "the possibilities, our answers will often be vacuous of meaningful content (e.g., “the patient can",
      "page": 39
    },
    {
      "level": "H5",
      "text": "have any of the following 573 diseases”). Thus, to obtain meaningful conclusions, we need",
      "page": 39
    },
    {
      "level": "H2",
      "text": "(cid:17) to reason not just about what is possible, but also about what is probable.",
      "page": 39
    },
    {
      "level": "H5",
      "text": "The calculus of probability theory (see section 2.1) provides us with a formal framework for",
      "page": 39
    },
    {
      "level": "H5",
      "text": "considering multiple possible outcomes and their likelihood. It deﬁnes a set of mutually exclusive",
      "page": 39
    },
    {
      "level": "H5",
      "text": "and exhaustive possibilities, and associates each of them with a probability — a number between",
      "page": 39
    },
    {
      "level": "H5",
      "text": "0 and 1, so that the total probability of all possibilities is 1. This framework allows us to consider",
      "page": 39
    },
    {
      "level": "H5",
      "text": "options that are unlikely, yet not impossible, without reducing our conclusions to content-free",
      "page": 39
    },
    {
      "level": "H5",
      "text": "lists of every possibility.",
      "page": 39
    },
    {
      "level": "H2",
      "text": "(cid:17) Furthermore, one ﬁnds that probabilistic models are very liberating. Where in a more",
      "page": 39
    },
    {
      "level": "H5",
      "text": "rigid formalism we might ﬁnd it necessary to enumerate every possibility, here we can",
      "page": 39
    },
    {
      "level": "H5",
      "text": "often sweep a multitude of annoying exceptions and special cases under the “probabilistic",
      "page": 39
    },
    {
      "level": "H5",
      "text": "rug,” by introducing outcomes that roughly correspond to “something unusual happens.”",
      "page": 39
    },
    {
      "level": "H5",
      "text": "In fact, as we discussed, this type of approximation is often inevitable, as we can only rarely",
      "page": 39
    },
    {
      "level": "H5",
      "text": "(if ever) provide a deterministic speciﬁcation of the behavior of a complex system. Probabilistic",
      "page": 39
    },
    {
      "level": "H5",
      "text": "models allow us to make this fact explicit, and therefore often provide a model which is more",
      "page": 39
    },
    {
      "level": "H5",
      "text": "faithful to reality.",
      "page": 39
    },
    {
      "level": "H4",
      "text": "1.2",
      "page": 39
    },
    {
      "level": "H4",
      "text": "Structured Probabilistic Models",
      "page": 39
    },
    {
      "level": "H5",
      "text": "This book describes a general-purpose framework for constructing and using probabilistic mod-",
      "page": 39
    },
    {
      "level": "H5",
      "text": "els of complex systems. We begin by providing some intuition for the principles underlying",
      "page": 39
    },
    {
      "level": "H5",
      "text": "this framework, and for the models it encompasses. This section requires some knowledge of",
      "page": 39
    },
    {
      "level": "H5",
      "text": "random variable",
      "page": 40
    },
    {
      "level": "H5",
      "text": "joint probability",
      "page": 40
    },
    {
      "level": "H5",
      "text": "distribution",
      "page": 40
    },
    {
      "level": "H5",
      "text": "posterior",
      "page": 40
    },
    {
      "level": "H5",
      "text": "distribution",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Example 1.1",
      "page": 40
    },
    {
      "level": "H5",
      "text": "1.2. Structured Probabilistic Models",
      "page": 40
    },
    {
      "level": "H5",
      "text": "basic concepts in probability theory; a reader unfamiliar with these concepts might wish to read",
      "page": 40
    },
    {
      "level": "H5",
      "text": "section 2.1 ﬁrst.",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Complex systems are characterized by the presence of multiple interrelated aspects, many of",
      "page": 40
    },
    {
      "level": "H5",
      "text": "which relate to the reasoning task. For example, in our medical diagnosis application, there",
      "page": 40
    },
    {
      "level": "H5",
      "text": "are multiple possible diseases that the patient might have, dozens or hundreds of symptoms",
      "page": 40
    },
    {
      "level": "H5",
      "text": "and diagnostic tests, personal characteristics that often form predisposing factors for disease,",
      "page": 40
    },
    {
      "level": "H5",
      "text": "and many more matters to consider. These domains can be characterized in terms of a set of",
      "page": 40
    },
    {
      "level": "H5",
      "text": "random variables, where the value of each variable deﬁnes an important property of the world.",
      "page": 40
    },
    {
      "level": "H5",
      "text": "For example, a particular disease, such as Flu, may be one variable in our domain, which takes",
      "page": 40
    },
    {
      "level": "H5",
      "text": "on two values, for example, present or absent; a symptom, such as Fever, may be a variable in",
      "page": 40
    },
    {
      "level": "H5",
      "text": "our domain, one that perhaps takes on continuous values. The set of possible variables and",
      "page": 40
    },
    {
      "level": "H5",
      "text": "their values is an important design decision, and it depends strongly on the questions we may",
      "page": 40
    },
    {
      "level": "H5",
      "text": "wish to answer about the domain.",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Our task is to reason probabilistically about the values of one or more of the variables,",
      "page": 40
    },
    {
      "level": "H5",
      "text": "possibly given observations about some others. In order to do so using principled probabilistic",
      "page": 40
    },
    {
      "level": "H5",
      "text": "reasoning, we need to construct a joint distribution over the space of possible assignments to",
      "page": 40
    },
    {
      "level": "H5",
      "text": "some set of random variables X . This type of model allows us to answer a broad range of",
      "page": 40
    },
    {
      "level": "H5",
      "text": "interesting queries. For example, we can make the observation that a variable Xi takes on the",
      "page": 40
    },
    {
      "level": "H5",
      "text": "speciﬁc value xi, and ask, in the resulting posterior distribution, what the probability distribution",
      "page": 40
    },
    {
      "level": "H5",
      "text": "is over values of another variable Xj.",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Consider a very simple medical diagnosis setting, where we focus on two diseases — ﬂu and",
      "page": 40
    },
    {
      "level": "H5",
      "text": "hayfever; these are not mutually exclusive, as a patient can have either, both, or none. Thus,",
      "page": 40
    },
    {
      "level": "H5",
      "text": "we might have two binary-valued random variables, Flu and Hayfever. We also have a 4-valued",
      "page": 40
    },
    {
      "level": "H5",
      "text": "random variable Season, which is correlated both with ﬂu and hayfever. We may also have two",
      "page": 40
    },
    {
      "level": "H5",
      "text": "symptoms, Congestion and Muscle Pain, each of which is also binary-valued. Overall, our probability",
      "page": 40
    },
    {
      "level": "H5",
      "text": "space has 2 × 2 × 4 × 2 × 2 = 64 values, corresponding to the possible assignments to these ﬁve",
      "page": 40
    },
    {
      "level": "H5",
      "text": "variables. Given a joint distribution over this space, we can, for example, ask questions such as how",
      "page": 40
    },
    {
      "level": "H5",
      "text": "likely the patient is to have the ﬂu given that it is fall, and that she has sinus congestion but no",
      "page": 40
    },
    {
      "level": "H5",
      "text": "muscle pain; as a probability expression, this query would be denoted",
      "page": 40
    },
    {
      "level": "H5",
      "text": "P (Flu = true | Season = fall, Congestion = true, Muscle Pain = false).",
      "page": 40
    },
    {
      "level": "H5",
      "text": "1.2.1",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Probabilistic Graphical Models",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Specifying a joint distribution over 64 possible values, as in example 1.1, already seems fairly",
      "page": 40
    },
    {
      "level": "H5",
      "text": "daunting. When we consider the fact that a typical medical- diagnosis problem has dozens or",
      "page": 40
    },
    {
      "level": "H5",
      "text": "even hundreds of relevant attributes, the problem appears completely intractable. This book",
      "page": 40
    },
    {
      "level": "H5",
      "text": "describes the framework of probabilistic graphical models, which provides a mechanism for",
      "page": 40
    },
    {
      "level": "H5",
      "text": "exploiting structure in complex distributions to describe them compactly, and in a way that",
      "page": 40
    },
    {
      "level": "H5",
      "text": "allows them to be constructed and utilized effectively.",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Probabilistic graphical models use a graph-based representation as the basis for compactly",
      "page": 40
    },
    {
      "level": "H5",
      "text": "encoding a complex distribution over a high-dimensional space. In this graphical representation,",
      "page": 40
    },
    {
      "level": "H5",
      "text": "illustrated in ﬁgure 1.1, the nodes (or ovals) correspond to the variables in our domain, and the",
      "page": 40
    },
    {
      "level": "H5",
      "text": "edges correspond to direct probabilistic interactions between them. For example, ﬁgure 1.1a (top)",
      "page": 40
    },
    {
      "level": "H5",
      "text": "Chapter 1.",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Bayesian networks",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Markov networks",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Graph Representation",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Independencies",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Factorization",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(F ⊥ H | S)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(C ⊥ S | F, H)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(M ⊥ H, C | F )",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(M ⊥ C | F )",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(A ⊥ C | B, D)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(B ⊥ D | A, C)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "P (S, F, H, C, M ) = P (S)P (F | S)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "P (H | S)P (C | F, H)P (M | F )",
      "page": 41
    },
    {
      "level": "H5",
      "text": "P (A, B, C, D) = 1",
      "page": 41
    },
    {
      "level": "H5",
      "text": "φ2(B, C)φ3(C, D)φ4(A, D)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(a)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(b)",
      "page": 41
    },
    {
      "level": "H5",
      "text": "Figure 1.1 Different perspectives on probabilistic graphical models: top — the graphical representa-",
      "page": 41
    },
    {
      "level": "H5",
      "text": "tion; middle — the independencies induced by the graph structure; bottom — the factorization induced",
      "page": 41
    },
    {
      "level": "H5",
      "text": "by the graph structure. (a) A sample Bayesian network. (b) A sample Markov network.",
      "page": 41
    },
    {
      "level": "H5",
      "text": "illustrates one possible graph structure for our ﬂu example. In this graph, we see that there is",
      "page": 41
    },
    {
      "level": "H5",
      "text": "no direct interaction between Muscle Pain and Season, but both interact directly with Flu.",
      "page": 41
    },
    {
      "level": "H5",
      "text": "There is a dual perspective that one can use to interpret the structure of this graph. From",
      "page": 41
    },
    {
      "level": "H5",
      "text": "one perspective, the graph is a compact representation of a set of independencies that hold",
      "page": 41
    },
    {
      "level": "H5",
      "text": "in the distribution; these properties take the form X is independent of Y given Z, denoted",
      "page": 41
    },
    {
      "level": "H5",
      "text": "(X ⊥ Y | Z), for some subsets of variables X, Y , Z. For example, our “target” distribution",
      "page": 41
    },
    {
      "level": "H5",
      "text": "P for the preceding example — the distribution encoding our beliefs about this particular",
      "page": 41
    },
    {
      "level": "H5",
      "text": "situation — may satisfy the conditional independence (Congestion ⊥ Season | Flu, Hayfever).",
      "page": 41
    },
    {
      "level": "H5",
      "text": "This statement asserts that",
      "page": 41
    },
    {
      "level": "H5",
      "text": "P (Congestion | Flu, Hayfever, Season) = P (Congestion | Flu, Hayfever);",
      "page": 41
    },
    {
      "level": "H5",
      "text": "that is, if we are interested in the distribution over the patient having congestion, and we know",
      "page": 41
    },
    {
      "level": "H5",
      "text": "whether he has the ﬂu and whether he has hayfever, the season is no longer informative. Note",
      "page": 41
    },
    {
      "level": "H5",
      "text": "that this assertion does not imply that Season is independent of Congestion; only that all of the",
      "page": 41
    },
    {
      "level": "H5",
      "text": "information we may obtain from the season on the chances of having congestion we already",
      "page": 41
    },
    {
      "level": "H5",
      "text": "obtain by knowing whether the patient has the ﬂu and has hayfever. Figure 1.1a (middle) shows",
      "page": 41
    },
    {
      "level": "H5",
      "text": "the set of independence assumptions associated with the graph in ﬁgure 1.1a (top).",
      "page": 41
    },
    {
      "level": "H5",
      "text": "1.2. Structured Probabilistic Models",
      "page": 42
    },
    {
      "level": "H5",
      "text": "factor",
      "page": 42
    },
    {
      "level": "H5",
      "text": "The other perspective is that the graph deﬁnes a skeleton for compactly representing a high-",
      "page": 42
    },
    {
      "level": "H5",
      "text": "dimensional distribution: Rather than encode the probability of every possible assignment to",
      "page": 42
    },
    {
      "level": "H5",
      "text": "all of the variables in our domain, we can “break up” the distribution into smaller factors, each",
      "page": 42
    },
    {
      "level": "H5",
      "text": "over a much smaller space of possibilities. We can then deﬁne the overall joint distribution",
      "page": 42
    },
    {
      "level": "H5",
      "text": "For example, ﬁgure 1.1(a-bottom) shows the factorization of",
      "page": 42
    },
    {
      "level": "H5",
      "text": "as a product of these factors.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "the distribution associated with the graph in ﬁgure 1.1 (top).",
      "page": 42
    },
    {
      "level": "H5",
      "text": "It asserts, for example, that",
      "page": 42
    },
    {
      "level": "H5",
      "text": "the probability of the event “spring, no ﬂu, hayfever, sinus congestion, muscle pain” can be",
      "page": 42
    },
    {
      "level": "H5",
      "text": "obtained by multiplying ﬁve numbers: P (Season = spring), P (Flu = false | Season = spring),",
      "page": 42
    },
    {
      "level": "H5",
      "text": "P (Hayfever = true | Season = spring), P (Congestion = true | Hayfever = true, Flu = false),",
      "page": 42
    },
    {
      "level": "H5",
      "text": "and P (Muscle Pain = true | Flu = false). This parameterization is signiﬁcantly more compact,",
      "page": 42
    },
    {
      "level": "H5",
      "text": "requiring only 3 + 4 + 4 + 4 + 2 = 17 nonredundant parameters, as opposed to 63 nonredundant",
      "page": 42
    },
    {
      "level": "H5",
      "text": "parameters for the original joint distribution (the 64th parameter is fully determined by the",
      "page": 42
    },
    {
      "level": "H5",
      "text": "others, as the sum over all entries in the joint distribution must sum to 1). The graph structure",
      "page": 42
    },
    {
      "level": "H5",
      "text": "deﬁnes the factorization of a distribution P associated with it — the set of factors and the",
      "page": 42
    },
    {
      "level": "H5",
      "text": "variables that they encompass.",
      "page": 42
    },
    {
      "level": "H2",
      "text": "(cid:17) It turns out that these two perspectives — the graph as a representation of a set of",
      "page": 42
    },
    {
      "level": "H5",
      "text": "independencies, and the graph as a skeleton for factorizing a distribution — are, in a",
      "page": 42
    },
    {
      "level": "H5",
      "text": "deep sense, equivalent. The independence properties of the distribution are precisely",
      "page": 42
    },
    {
      "level": "H5",
      "text": "what allow it to be represented compactly in a factorized form. Conversely, a particular",
      "page": 42
    },
    {
      "level": "H5",
      "text": "factorization of the distribution guarantees that certain independencies hold.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "Bayesian network",
      "page": 42
    },
    {
      "level": "H5",
      "text": "Markov network",
      "page": 42
    },
    {
      "level": "H5",
      "text": "We describe two families of graphical representations of distributions. One, called Bayesian",
      "page": 42
    },
    {
      "level": "H5",
      "text": "networks, uses a directed graph (where the edges have a source and a target), as shown in",
      "page": 42
    },
    {
      "level": "H5",
      "text": "ﬁgure 1.1a (top). The second, called Markov networks, uses an undirected graph, as illustrated in",
      "page": 42
    },
    {
      "level": "H5",
      "text": "It too can be viewed as deﬁning a set of independence assertions (ﬁgure 1.1b",
      "page": 42
    },
    {
      "level": "H5",
      "text": "ﬁgure 1.1b (top).",
      "page": 42
    },
    {
      "level": "H5",
      "text": "[middle] or as encoding a compact factorization of the distribution (ﬁgure 1.1b [bottom]). Both",
      "page": 42
    },
    {
      "level": "H5",
      "text": "representations provide the duality of independencies and factorization, but they differ in the",
      "page": 42
    },
    {
      "level": "H5",
      "text": "set of independencies they can encode and in the factorization of the distribution that they",
      "page": 42
    },
    {
      "level": "H5",
      "text": "induce.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "1.2.2",
      "page": 42
    },
    {
      "level": "H5",
      "text": "Representation, Inference, Learning",
      "page": 42
    },
    {
      "level": "H5",
      "text": "The graphical language exploits structure that appears present in many distributions that we",
      "page": 42
    },
    {
      "level": "H5",
      "text": "want to encode in practice: the property that variables tend to interact directly only with very",
      "page": 42
    },
    {
      "level": "H5",
      "text": "few others. Distributions that exhibit this type of structure can generally be encoded naturally",
      "page": 42
    },
    {
      "level": "H5",
      "text": "and compactly using a graphical model.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "This framework has many advantages. First, it often allows the distribution to be written",
      "page": 42
    },
    {
      "level": "H5",
      "text": "down tractably, even in cases where the explicit representation of the joint distribution is",
      "page": 42
    },
    {
      "level": "H5",
      "text": "astronomically large.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "Importantly, the type of representation provided by this framework is",
      "page": 42
    },
    {
      "level": "H5",
      "text": "transparent, in that a human expert can understand and evaluate its semantics and properties.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "This property is important for constructing models that provide an accurate reﬂection of our",
      "page": 42
    },
    {
      "level": "H5",
      "text": "understanding of a domain. Models that are opaque can easily give rise to unexplained, and",
      "page": 42
    },
    {
      "level": "H5",
      "text": "even undesirable, answers.",
      "page": 42
    },
    {
      "level": "H5",
      "text": "Second, as we show, the same structure often also allows the distribution to be used effectively",
      "page": 42
    },
    {
      "level": "H5",
      "text": "for inference — answering queries using the distribution as our model of the world. In particular,",
      "page": 42
    },
    {
      "level": "H5",
      "text": "we provide algorithms for computing the posterior probability of some variables given evidence",
      "page": 42
    },
    {
      "level": "H5",
      "text": "inference",
      "page": 42
    },
    {
      "level": "H5",
      "text": "data-driven",
      "page": 43
    },
    {
      "level": "H5",
      "text": "approach",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Chapter 1.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 43
    },
    {
      "level": "H5",
      "text": "on others. For example, we might observe that it is spring and the patient has muscle pain,",
      "page": 43
    },
    {
      "level": "H5",
      "text": "and we wish to know how likely he is to have the ﬂu, a query that can formally be written as",
      "page": 43
    },
    {
      "level": "H5",
      "text": "P (Flu = true | Season = spring, Muscle Pain = true). These inference algorithms work directly",
      "page": 43
    },
    {
      "level": "H5",
      "text": "on the graph structure and are generally orders of magnitude faster than manipulating the joint",
      "page": 43
    },
    {
      "level": "H5",
      "text": "distribution explicitly.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Third, this framework facilitates the effective construction of these models, whether by a hu-",
      "page": 43
    },
    {
      "level": "H5",
      "text": "man expert or automatically, by learning from data a model that provides a good approximation",
      "page": 43
    },
    {
      "level": "H5",
      "text": "to our past experience. For example, we may have a set of patient records from a doctor’s office",
      "page": 43
    },
    {
      "level": "H5",
      "text": "and wish to learn a probabilistic model encoding a distribution consistent with our aggregate",
      "page": 43
    },
    {
      "level": "H5",
      "text": "experience. Probabilistic graphical models support a data-driven approach to model construction",
      "page": 43
    },
    {
      "level": "H5",
      "text": "that is very effective in practice. In this approach, a human expert provides some rough guide-",
      "page": 43
    },
    {
      "level": "H5",
      "text": "lines on how to model a given domain. For example, the human usually speciﬁes the attributes",
      "page": 43
    },
    {
      "level": "H5",
      "text": "that the model should contain, often some of the main dependencies that it should encode, and",
      "page": 43
    },
    {
      "level": "H5",
      "text": "perhaps other aspects. The details, however, are usually ﬁlled in automatically, by ﬁtting the",
      "page": 43
    },
    {
      "level": "H5",
      "text": "model to data. The models produced by this process are usually much better reﬂections of the",
      "page": 43
    },
    {
      "level": "H5",
      "text": "domain than models that are purely hand-constructed. Moreover, they can sometimes reveal",
      "page": 43
    },
    {
      "level": "H5",
      "text": "surprising connections between variables and provide novel insights about a domain.",
      "page": 43
    },
    {
      "level": "H2",
      "text": "(cid:17) These three components — representation, inference, and learning — are critical com-",
      "page": 43
    },
    {
      "level": "H5",
      "text": "ponents in constructing an intelligent system. We need a declarative representation that",
      "page": 43
    },
    {
      "level": "H5",
      "text": "is a reasonable encoding of our world model. We need to be able to use this representa-",
      "page": 43
    },
    {
      "level": "H5",
      "text": "tion effectively to answer a broad range of questions that are of interest. And we need to",
      "page": 43
    },
    {
      "level": "H5",
      "text": "be able to acquire this distribution, combining expert knowledge and accumulated data.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Probabilistic graphical models are one of a small handful of frameworks that support all",
      "page": 43
    },
    {
      "level": "H5",
      "text": "three capabilities for a broad range of problems.",
      "page": 43
    },
    {
      "level": "H4",
      "text": "1.3 Overview and Roadmap",
      "page": 43
    },
    {
      "level": "H5",
      "text": "1.3.1",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Overview of Chapters",
      "page": 43
    },
    {
      "level": "H5",
      "text": "The framework of probabilistic graphical models is quite broad, and it encompasses both a",
      "page": 43
    },
    {
      "level": "H5",
      "text": "variety of different types of models and a range of methods relating to them. This book",
      "page": 43
    },
    {
      "level": "H5",
      "text": "describes several types of models. For each one, we describe the three fundamental cornerstones:",
      "page": 43
    },
    {
      "level": "H5",
      "text": "representation, inference, and learning.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "We begin in part I, by describing the most basic type of graphical models, which are the focus",
      "page": 43
    },
    {
      "level": "H5",
      "text": "of most of the book. These models encode distributions over a ﬁxed set X of random variables.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "We describe how graphs can be used to encode distributions over such spaces, and what the",
      "page": 43
    },
    {
      "level": "H5",
      "text": "properties of such distributions are.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Speciﬁcally, in chapter 3, we describe the Bayesian network representation, based on directed",
      "page": 43
    },
    {
      "level": "H5",
      "text": "graphs. We describe how a Bayesian network can encode a probability distribution. We also",
      "page": 43
    },
    {
      "level": "H5",
      "text": "analyze the independence properties induced by the graph structure.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "In chapter 4, we move to Markov networks, the other main category of probabilistic graphical",
      "page": 43
    },
    {
      "level": "H5",
      "text": "models. Here also we describe the independencies deﬁned by the graph and the induced",
      "page": 43
    },
    {
      "level": "H5",
      "text": "factorization of the distribution. We also discuss the relationship between Markov networks and",
      "page": 43
    },
    {
      "level": "H5",
      "text": "Bayesian networks, and brieﬂy describe a framework that uniﬁes both.",
      "page": 43
    },
    {
      "level": "H5",
      "text": "In chapter 5, we delve a little deeper into the representation of the parameters in probabilistic",
      "page": 43
    },
    {
      "level": "H5",
      "text": "1.3. Overview and Roadmap",
      "page": 44
    },
    {
      "level": "H5",
      "text": "models, focusing mostly on Bayesian networks, whose parameterization is more constrained. We",
      "page": 44
    },
    {
      "level": "H5",
      "text": "describe representations that capture some of the ﬁner-grained structure of the distribution, and",
      "page": 44
    },
    {
      "level": "H5",
      "text": "show that, here also, capturing structure can provide signiﬁcant gains.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "In chapter 6, we turn to formalisms that extend the basic framework of probabilistic graphical",
      "page": 44
    },
    {
      "level": "H5",
      "text": "models to settings where the set of variables is no longer rigidly circumscribed in advance.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "One such setting is a temporal one, where we wish to model a system whose state evolves",
      "page": 44
    },
    {
      "level": "H5",
      "text": "over time, requiring us to consider distributions over entire trajectories, We describe a compact",
      "page": 44
    },
    {
      "level": "H5",
      "text": "representation — a dynamic Bayesian network — that allows us to represent structured systems",
      "page": 44
    },
    {
      "level": "H5",
      "text": "that evolve over time. We then describe a family of extensions that introduce various forms",
      "page": 44
    },
    {
      "level": "H5",
      "text": "of higher level structure into the framework of probabilistic graphical models. Speciﬁcally, we",
      "page": 44
    },
    {
      "level": "H5",
      "text": "focus on domains containing objects (whether concrete or abstract), characterized by attributes,",
      "page": 44
    },
    {
      "level": "H5",
      "text": "and related to each other in various ways. Such domains can include repeated structure, since",
      "page": 44
    },
    {
      "level": "H5",
      "text": "different objects of the same type share the same probabilistic model. These languages provide",
      "page": 44
    },
    {
      "level": "H5",
      "text": "a signiﬁcant extension to the expressive power of the standard graphical models.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "In chapter 7, we take a deeper look at models that include continuous variables. Speciﬁcally,",
      "page": 44
    },
    {
      "level": "H5",
      "text": "we explore the properties of the multivariate Gaussian distribution and the representation of",
      "page": 44
    },
    {
      "level": "H5",
      "text": "such distributions as both directed and undirected graphical models. Although the class of",
      "page": 44
    },
    {
      "level": "H5",
      "text": "Gaussian distributions is a limited one and not suitable for all applications, it turns out to play",
      "page": 44
    },
    {
      "level": "H5",
      "text": "a critical role even when dealing with distributions that are not Gaussian.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "In chapter 8, we take a deeper, more technical look at probabilistic models, deﬁning a general",
      "page": 44
    },
    {
      "level": "H5",
      "text": "framework called the exponential family, that encompasses a broad range of distributions. This",
      "page": 44
    },
    {
      "level": "H5",
      "text": "chapter provides some basic concepts and tools that will turn out to play an important role in",
      "page": 44
    },
    {
      "level": "H5",
      "text": "later development.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "We then turn, in part II, to a discussion of the inference task.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "In chapter 9, we describe",
      "page": 44
    },
    {
      "level": "H5",
      "text": "the basic ideas underlying exact inference in probabilistic graphical models. We ﬁrst analyze",
      "page": 44
    },
    {
      "level": "H5",
      "text": "the fundamental difficulty of the exact inference task, separately from any particular inference",
      "page": 44
    },
    {
      "level": "H5",
      "text": "algorithm we might develop. We then present two basic algorithms for exact inference —",
      "page": 44
    },
    {
      "level": "H5",
      "text": "variable elimination and conditioning — both of which are equally applicable to both directed",
      "page": 44
    },
    {
      "level": "H5",
      "text": "and undirected models. Both of these algorithms can be viewed as operating over the graph",
      "page": 44
    },
    {
      "level": "H5",
      "text": "structure deﬁned by the probabilistic model. They build on basic concepts, such as graph",
      "page": 44
    },
    {
      "level": "H5",
      "text": "properties and dynamic programming algorithms, to provide efficient solutions to the inference",
      "page": 44
    },
    {
      "level": "H5",
      "text": "task. We also provide an analysis of their computational cost in terms of the graph structure,",
      "page": 44
    },
    {
      "level": "H5",
      "text": "and we discuss where exact inference is feasible.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "In chapter 10, we describe an alternative view of exact inference,",
      "page": 44
    },
    {
      "level": "H5",
      "text": "leading to a somewhat",
      "page": 44
    },
    {
      "level": "H5",
      "text": "different algorithm. The beneﬁt of this alternative algorithm is twofold. First, it uses dynamic",
      "page": 44
    },
    {
      "level": "H5",
      "text": "programming to avoid repeated computations in settings where we wish to answer more than a",
      "page": 44
    },
    {
      "level": "H5",
      "text": "single query using the same network. Second, it deﬁnes a natural algorithm that uses message",
      "page": 44
    },
    {
      "level": "H5",
      "text": "passing on a graph structure; this algorithm forms the basis for approximate inference algorithms",
      "page": 44
    },
    {
      "level": "H5",
      "text": "developed in later chapters.",
      "page": 44
    },
    {
      "level": "H5",
      "text": "Because exact inference is computationally intractable for many models of interest, we then",
      "page": 44
    },
    {
      "level": "H5",
      "text": "proceed to describe approximate inference algorithms, which trade off accuracy with computa-",
      "page": 44
    },
    {
      "level": "H5",
      "text": "tional cost. We present two main classes of such algorithms. In chapter 11, we describe a class",
      "page": 44
    },
    {
      "level": "H5",
      "text": "of methods that can be viewed from two very different perspectives: On one hand, they are",
      "page": 44
    },
    {
      "level": "H5",
      "text": "direct generalizations of the graph-based message-passing approach developed for the case of",
      "page": 44
    },
    {
      "level": "H5",
      "text": "exact inference in chapter 10. On the other hand, they can be viewed as solving an optimization",
      "page": 44
    },
    {
      "level": "H5",
      "text": "Chapter 1.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 45
    },
    {
      "level": "H5",
      "text": "problem: one where we approximate the distribution of interest using a simpler representation",
      "page": 45
    },
    {
      "level": "H5",
      "text": "that allows for feasible inference. The equivalence of these views provides important insights",
      "page": 45
    },
    {
      "level": "H5",
      "text": "and suggests a broad family of algorithms that one can apply to approximate inference.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "In chapter 12, we describe a very different class of methods: particle-based methods, which",
      "page": 45
    },
    {
      "level": "H5",
      "text": "approximate a complex joint distribution by considering samples from it (also known as par-",
      "page": 45
    },
    {
      "level": "H5",
      "text": "ticles). We describe several methods from this general family. These methods are generally",
      "page": 45
    },
    {
      "level": "H5",
      "text": "based on core techniques from statistics, such as importance sampling and Markov-chain Monte",
      "page": 45
    },
    {
      "level": "H5",
      "text": "Carlo methods. Once again, the connection to this general class of methods suggests multiple",
      "page": 45
    },
    {
      "level": "H5",
      "text": "opportunities for new algorithms.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "While the representation of probabilistic graphical models applies, to a great extent, to models",
      "page": 45
    },
    {
      "level": "H5",
      "text": "including both discrete and continuous-valued random variables, inference in models involving",
      "page": 45
    },
    {
      "level": "H5",
      "text": "continuous variables is signiﬁcantly more challenging than the purely discrete case. In chapter 14,",
      "page": 45
    },
    {
      "level": "H5",
      "text": "we consider the task of inference in continuous and hybrid (continuous/discrete) networks, and",
      "page": 45
    },
    {
      "level": "H5",
      "text": "we discuss whether and how the exact and approximate inference methods developed in earlier",
      "page": 45
    },
    {
      "level": "H5",
      "text": "chapters can be applied in this setting.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "The representation that we discussed in chapter 6 allows a compact encoding of networks",
      "page": 45
    },
    {
      "level": "H5",
      "text": "whose size can be unboundedly large. Such networks pose particular challenges to inference",
      "page": 45
    },
    {
      "level": "H5",
      "text": "algorithms. In this chapter, we discuss some special-purpose methods that have been developed",
      "page": 45
    },
    {
      "level": "H5",
      "text": "for the particular settings of networks that model dynamical systems.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "We then turn, in part III, to the third of our main topics — learning probabilistic models from",
      "page": 45
    },
    {
      "level": "H5",
      "text": "data. We begin in chapter 16 by reviewing some of the fundamental concepts underlying the",
      "page": 45
    },
    {
      "level": "H5",
      "text": "general task of learning models from data. We then present the spectrum of learning problems",
      "page": 45
    },
    {
      "level": "H5",
      "text": "that we address in this part of the book. These problems vary along two main axes: the extent to",
      "page": 45
    },
    {
      "level": "H5",
      "text": "which we are given prior knowledge specifying the model, and whether the data from which we",
      "page": 45
    },
    {
      "level": "H5",
      "text": "learn contain complete observations of all of the relevant variables. In contrast to the inference",
      "page": 45
    },
    {
      "level": "H5",
      "text": "task, where the same algorithms apply equally to Bayesian networks and Markov networks, the",
      "page": 45
    },
    {
      "level": "H5",
      "text": "learning task is quite different for these two classes of models. We begin with studying the",
      "page": 45
    },
    {
      "level": "H5",
      "text": "learning task for Bayesian networks.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "In chapter 17, we focus on the most basic learning task:",
      "page": 45
    },
    {
      "level": "H5",
      "text": "learning parameters for a Bayesian",
      "page": 45
    },
    {
      "level": "H5",
      "text": "network with a given structure, from fully observable data. Although this setting may appear",
      "page": 45
    },
    {
      "level": "H5",
      "text": "somewhat restrictive,",
      "page": 45
    },
    {
      "level": "H5",
      "text": "it turns out to form the basis for our entire development of Bayesian",
      "page": 45
    },
    {
      "level": "H5",
      "text": "network learning. As we show, the factorization of the distribution, which was central both to",
      "page": 45
    },
    {
      "level": "H5",
      "text": "representation and to inference, also plays a key role in making inference feasible.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "We then move,",
      "page": 45
    },
    {
      "level": "H5",
      "text": "in chapter 18, to the harder problem of learning both Bayesian network",
      "page": 45
    },
    {
      "level": "H5",
      "text": "structure and the parameters, still from fully observed data. The learning algorithms we present",
      "page": 45
    },
    {
      "level": "H5",
      "text": "trade off the accuracy with which the learned network represents the empirical distribution for",
      "page": 45
    },
    {
      "level": "H5",
      "text": "the complexity of the resulting structure. As we show, the type of independence assumptions",
      "page": 45
    },
    {
      "level": "H5",
      "text": "underlying the Bayesian network representation often hold, at least approximately, in real-world",
      "page": 45
    },
    {
      "level": "H5",
      "text": "distributions. Thus, these learning algorithms often result in reasonably compact structures that",
      "page": 45
    },
    {
      "level": "H5",
      "text": "capture much of the signal in the distribution.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "In chapter 19, we address the Bayesian network learning task in a setting where we have",
      "page": 45
    },
    {
      "level": "H5",
      "text": "access only to partial observations of the relevant variables (for example, when the available",
      "page": 45
    },
    {
      "level": "H5",
      "text": "patient records have missing entries). This type of situation occurs often in real-world settings.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "Unfortunately, the resulting learning task is considerably harder, and the resulting algorithms are",
      "page": 45
    },
    {
      "level": "H5",
      "text": "both more complex and less satisfactory in terms of their performance.",
      "page": 45
    },
    {
      "level": "H5",
      "text": "1.3. Overview and Roadmap",
      "page": 46
    },
    {
      "level": "H5",
      "text": "We conclude the discussion of learning in chapter 20 by considering the problem of learning",
      "page": 46
    },
    {
      "level": "H5",
      "text": "Markov networks from data.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "It turns out that the learning tasks for Markov networks are",
      "page": 46
    },
    {
      "level": "H5",
      "text": "signiﬁcantly harder than the corresponding problem for Bayesian networks. We explain the",
      "page": 46
    },
    {
      "level": "H5",
      "text": "difficulties and discuss the existing solutions.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "Finally, in part IV, we turn to a different type of extension, where we consider the use of this",
      "page": 46
    },
    {
      "level": "H5",
      "text": "framework for other forms of reasoning. Speciﬁcally, we consider cases where we can act, or",
      "page": 46
    },
    {
      "level": "H5",
      "text": "intervene, in the world.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "In chapter 21, we focus on the semantics of intervention and its relation to causality. We",
      "page": 46
    },
    {
      "level": "H5",
      "text": "present the notion of a causal model, which allows us to answer not only queries of the form “if",
      "page": 46
    },
    {
      "level": "H5",
      "text": "I observe X, what do I learn about Y,” but also intervention queries, of the form “if I manipulate",
      "page": 46
    },
    {
      "level": "H5",
      "text": "X, what effect does it have on Y.”",
      "page": 46
    },
    {
      "level": "H5",
      "text": "We then turn to the task of decision making under uncertainty. Here, we must consider not",
      "page": 46
    },
    {
      "level": "H5",
      "text": "only the distribution over different states of the world, but also the preferences of the agent",
      "page": 46
    },
    {
      "level": "H5",
      "text": "regarding these outcomes.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "In chapter 22, we discuss the notion of utility functions and how",
      "page": 46
    },
    {
      "level": "H5",
      "text": "they can encode an agent’s preferences about complex situations involving multiple variables.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "As we show, the same ideas that we used to provide compact representations of probability",
      "page": 46
    },
    {
      "level": "H5",
      "text": "distribution can also be used for utility functions.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "In chapter 23, we describe a uniﬁed representation for decision making, called inﬂuence",
      "page": 46
    },
    {
      "level": "H5",
      "text": "diagrams. Inﬂuence diagrams extend Bayesian networks by introducing actions and utilities. We",
      "page": 46
    },
    {
      "level": "H5",
      "text": "present algorithms that use inﬂuence diagrams for making decisions that optimize the agent’s",
      "page": 46
    },
    {
      "level": "H5",
      "text": "expected utility. These algorithms utilize many of the same ideas that formed the basis for exact",
      "page": 46
    },
    {
      "level": "H5",
      "text": "inference in Bayesian networks.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "We conclude with a high-level synthesis of the techniques covered in this book, and with",
      "page": 46
    },
    {
      "level": "H5",
      "text": "some guidance on how to use them in tackling a new problem.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "1.3.2",
      "page": 46
    },
    {
      "level": "H5",
      "text": "Reader’s Guide",
      "page": 46
    },
    {
      "level": "H5",
      "text": "As we mentioned, the topics described in this book relate to multiple ﬁelds, and techniques",
      "page": 46
    },
    {
      "level": "H5",
      "text": "from other disciplines — probability theory, computer science, information theory, optimization,",
      "page": 46
    },
    {
      "level": "H5",
      "text": "statistics, and more — are used in various places throughout it. While it is impossible to present",
      "page": 46
    },
    {
      "level": "H5",
      "text": "all of the relevant material within the scope of this book, we have attempted to make the book",
      "page": 46
    },
    {
      "level": "H5",
      "text": "somewhat self-contained by providing a very brief review of the key concepts from these related",
      "page": 46
    },
    {
      "level": "H5",
      "text": "disciplines in chapter 2.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "Some of this material, speciﬁcally the review of probability theory and of graph-related con-",
      "page": 46
    },
    {
      "level": "H5",
      "text": "cepts, is very basic yet central to most of the development in this book. Readers who are less",
      "page": 46
    },
    {
      "level": "H5",
      "text": "familiar with these topics may wish to read these sections carefully, and even knowledgeable",
      "page": 46
    },
    {
      "level": "H5",
      "text": "readers may wish to brieﬂy review them to gain familiarity with the notations used. Other",
      "page": 46
    },
    {
      "level": "H5",
      "text": "background material, covering such topics as information theory, optimization, and algorithmic",
      "page": 46
    },
    {
      "level": "H5",
      "text": "concepts, can be found in the appendix.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "The chapters in the book are structured as follows. The main text in each chapter provides the",
      "page": 46
    },
    {
      "level": "H5",
      "text": "detailed technical development of the key ideas. Beyond the main text, most chapters contain",
      "page": 46
    },
    {
      "level": "H5",
      "text": "boxes that contain interesting material that augments these ideas. These boxes come in three",
      "page": 46
    },
    {
      "level": "H5",
      "text": "types: Skill boxes describe “hands-on” tricks and techniques, which, while often heuristic in",
      "page": 46
    },
    {
      "level": "H5",
      "text": "nature, are important for getting the basic algorithms described in the text to work in practice.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "Case study boxes describe empirical case studies relating to the techniques described in the text.",
      "page": 46
    },
    {
      "level": "H5",
      "text": "Chapter 1.",
      "page": 47
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 47
    },
    {
      "level": "H5",
      "text": "Figure 1.2 A reader’s guide to the structure and dependencies in this book",
      "page": 47
    },
    {
      "level": "H5",
      "text": "These case studies include both empirical results on how the algorithms perform in practice",
      "page": 47
    },
    {
      "level": "H5",
      "text": "and descriptions of applications of these algorithms to interesting domains, illustrating some of",
      "page": 47
    },
    {
      "level": "H5",
      "text": "the issues encountered in practice. Finally, concept boxes present particular instantiations of the",
      "page": 47
    },
    {
      "level": "H5",
      "text": "material described in the text, which have had signiﬁcant impact in their own right.",
      "page": 47
    },
    {
      "level": "H5",
      "text": "This textbook is clearly too long to be used in its entirety in a one-semester class. Figure 1.2",
      "page": 47
    },
    {
      "level": "H5",
      "text": "tries to delineate some coherent subsets of the book that can be used for teaching and other",
      "page": 47
    },
    {
      "level": "H5",
      "text": "purposes. The small, labeled boxes represent “units” of material on particular topics. Arrows",
      "page": 47
    },
    {
      "level": "H5",
      "text": "between the boxes represent dependencies between these units. The ﬁrst enclosing box (solid",
      "page": 47
    },
    {
      "level": "H5",
      "text": "line) represents material that is fundamental to everything else, and that should be read by",
      "page": 47
    },
    {
      "level": "H5",
      "text": "anyone using this book. One can then use the dependencies between the boxes to expand or",
      "page": 47
    },
    {
      "level": "H5",
      "text": "reduce the depth of the coverage on any given topic. The material in the larger box (dashed",
      "page": 47
    },
    {
      "level": "H5",
      "text": "line) forms a good basis for a one-semester (or even one-quarter) overview class. Some of the",
      "page": 47
    },
    {
      "level": "H5",
      "text": "sections in the book are marked with an asterisk, denoting the fact that they contain more",
      "page": 47
    },
    {
      "level": "H5",
      "text": "technically advanced material. In most cases, these sections are self-contained, and they can be",
      "page": 47
    },
    {
      "level": "H5",
      "text": "skipped without harming the reader’s ability to understand the rest of the text.",
      "page": 47
    },
    {
      "level": "H5",
      "text": "We have attempted in this book to present a synthesis of ideas, most of which have been",
      "page": 47
    },
    {
      "level": "H5",
      "text": "developed over many years by multiple researchers. To avoid futile attempts to divide up the",
      "page": 47
    },
    {
      "level": "H5",
      "text": "credit precisely, we have omitted all bibliographical references from the technical presentation",
      "page": 47
    },
    {
      "level": "H5",
      "text": "1.3. Overview and Roadmap",
      "page": 48
    },
    {
      "level": "H5",
      "text": "in the chapters. Rather, each chapter ends with a section called “Relevant Literature,” which",
      "page": 48
    },
    {
      "level": "H5",
      "text": "describes the historical evolution of the material in the chapter, acknowledges the papers and",
      "page": 48
    },
    {
      "level": "H5",
      "text": "books that developed the key concepts, and provides some additional readings on material",
      "page": 48
    },
    {
      "level": "H5",
      "text": "relevant to the chapter. We encourage the reader who is interested in a topic to follow up on",
      "page": 48
    },
    {
      "level": "H5",
      "text": "some of these additional readings, since there are many interesting developments that we could",
      "page": 48
    },
    {
      "level": "H5",
      "text": "not cover in this book.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Finally, each chapter includes a set of exercises that explore in additional depth some of the",
      "page": 48
    },
    {
      "level": "H5",
      "text": "material described in the text and present some extensions to it. The exercises are annotated",
      "page": 48
    },
    {
      "level": "H5",
      "text": "with an asterisk for exercises that are somewhat more difficult, and with two asterisks for ones",
      "page": 48
    },
    {
      "level": "H5",
      "text": "that are truly challenging.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Additional material related to this book, including slides and ﬁgures, solutions to some of the",
      "page": 48
    },
    {
      "level": "H5",
      "text": "exercises, and errata, can be found online at http://pgm.stanford.edu.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "1.3.3",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Connection to Other Disciplines",
      "page": 48
    },
    {
      "level": "H5",
      "text": "The ideas we describe in this book are connected to many ﬁelds. From probability theory, we",
      "page": 48
    },
    {
      "level": "H5",
      "text": "inherit the basic concept of a probability distribution, as well as many of the operations we",
      "page": 48
    },
    {
      "level": "H5",
      "text": "can use to manipulate it. From computer science, we exploit the key idea of using a graph",
      "page": 48
    },
    {
      "level": "H5",
      "text": "as a data structure, as well as a variety of algorithms for manipulating graphs and other data",
      "page": 48
    },
    {
      "level": "H5",
      "text": "structures. These algorithmic ideas and the ability to manipulate probability distributions using",
      "page": 48
    },
    {
      "level": "H5",
      "text": "discrete data structures are some of the key elements that make the probabilistic manipulations",
      "page": 48
    },
    {
      "level": "H5",
      "text": "tractable. Decision theory extends these basic ideas to the task of decision making under",
      "page": 48
    },
    {
      "level": "H5",
      "text": "uncertainty and provides the formal foundation for this task.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "From computer science, and speciﬁcally from artiﬁcial intelligence, these models inherit the",
      "page": 48
    },
    {
      "level": "H5",
      "text": "idea of using a declarative representation of the world to separate procedural reasoning from",
      "page": 48
    },
    {
      "level": "H5",
      "text": "our domain knowledge. This idea is of key importance to the generality of this framework and",
      "page": 48
    },
    {
      "level": "H5",
      "text": "its applicability to such a broad range of tasks.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Various ideas from other disciplines also arise in this ﬁeld. Statistics plays an important role",
      "page": 48
    },
    {
      "level": "H5",
      "text": "both in certain aspects of the representation and in some of the work on learning models from",
      "page": 48
    },
    {
      "level": "H5",
      "text": "data. Optimization plays a role in providing algorithms both for approximate inference and for",
      "page": 48
    },
    {
      "level": "H5",
      "text": "learning models from data. Bayesian networks ﬁrst arose, albeit in a restricted way, in the setting",
      "page": 48
    },
    {
      "level": "H5",
      "text": "of modeling genetic inheritance in human family trees; in fact, restricted version of some of the",
      "page": 48
    },
    {
      "level": "H5",
      "text": "exact inference algorithms we discuss were ﬁrst developed in this context. Similarly, undirected",
      "page": 48
    },
    {
      "level": "H5",
      "text": "graphical models ﬁrst arose in physics as a model for systems of electrons, and some of the",
      "page": 48
    },
    {
      "level": "H5",
      "text": "basic concepts that underlie recent work on approximate inference developed from that setting.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Information-theoretic",
      "page": 48
    },
    {
      "level": "H5",
      "text": "concepts such as entropy and information arise naturally in various settings in this framework,",
      "page": 48
    },
    {
      "level": "H5",
      "text": "such as evaluating the quality of a learned model. Thus, tools from this discipline are a key",
      "page": 48
    },
    {
      "level": "H5",
      "text": "component in our analytic toolkit. On the other side, the recent successes in coding theory,",
      "page": 48
    },
    {
      "level": "H5",
      "text": "based on the relationship between inference in probabilistic models and the task of decoding",
      "page": 48
    },
    {
      "level": "H5",
      "text": "messages sent over a noisy channel, have led to a resurgence of work on approximate inference",
      "page": 48
    },
    {
      "level": "H5",
      "text": "in graphical models. The resulting developments have revolutionized both the development of",
      "page": 48
    },
    {
      "level": "H5",
      "text": "error-correcting codes and the theory and practice of approximate message-passing algorithms",
      "page": 48
    },
    {
      "level": "H5",
      "text": "in graphical models.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Information theory plays a dual role in its interaction with this ﬁeld.",
      "page": 48
    },
    {
      "level": "H5",
      "text": "Chapter 1.",
      "page": 49
    },
    {
      "level": "H5",
      "text": "Introduction",
      "page": 49
    },
    {
      "level": "H5",
      "text": "1.3.3.1 What Have We Gained?",
      "page": 49
    },
    {
      "level": "H5",
      "text": "Although the framework we describe here shares common elements with a broad range of",
      "page": 49
    },
    {
      "level": "H5",
      "text": "other topics, it has a coherent common core: the use of structure to allow a compact repre-",
      "page": 49
    },
    {
      "level": "H5",
      "text": "sentation, effective reasoning, and feasible learning of general-purpose, factored, probabilistic",
      "page": 49
    },
    {
      "level": "H5",
      "text": "models. These elements provide us with a general infrastructure for reasoning and learning",
      "page": 49
    },
    {
      "level": "H5",
      "text": "about complex domains.",
      "page": 49
    },
    {
      "level": "H5",
      "text": "As we discussed earlier, by using a declarative representation, we essentially separate out the",
      "page": 49
    },
    {
      "level": "H5",
      "text": "description of the model for the particular application, and the general-purpose algorithms used",
      "page": 49
    },
    {
      "level": "H5",
      "text": "for inference and learning. Thus, this framework provides a general algorithmic toolkit that can",
      "page": 49
    },
    {
      "level": "H5",
      "text": "be applied to many different domains.",
      "page": 49
    },
    {
      "level": "H5",
      "text": "Indeed, probabilistic graphical models have made a signiﬁcant impact on a broad spectrum",
      "page": 49
    },
    {
      "level": "H5",
      "text": "of real-world applications. For example, these models have been used for medical and fault",
      "page": 49
    },
    {
      "level": "H5",
      "text": "diagnosis, for modeling human genetic inheritance of disease, for segmenting and denoising",
      "page": 49
    },
    {
      "level": "H5",
      "text": "images, for decoding messages sent over a noisy channel, for revealing genetic regulatory pro-",
      "page": 49
    },
    {
      "level": "H5",
      "text": "cesses, for robot localization and mapping, and more. Throughout this book, we will describe",
      "page": 49
    },
    {
      "level": "H5",
      "text": "how probabilistic graphical models were used to address these applications and what issues",
      "page": 49
    },
    {
      "level": "H5",
      "text": "arise in the application of these models in practice.",
      "page": 49
    },
    {
      "level": "H5",
      "text": "In addition to practical applications, these models provide a formal framework for a variety",
      "page": 49
    },
    {
      "level": "H5",
      "text": "of fundamental problems. For example, the notion of conditional independence and its explicit",
      "page": 49
    },
    {
      "level": "H5",
      "text": "graph-based representation provide a clear formal semantics for irrelevance of information. This",
      "page": 49
    },
    {
      "level": "H5",
      "text": "framework also provides a general methodology for handling data fusion — we can introduce",
      "page": 49
    },
    {
      "level": "H5",
      "text": "sensor variables that are noisy versions of the true measured quantity, and use Bayesian condi-",
      "page": 49
    },
    {
      "level": "H5",
      "text": "tioning to combine the different measurements. The use of a probabilistic model allows us to",
      "page": 49
    },
    {
      "level": "H5",
      "text": "provide a formal measure for model quality, in terms of a numerical ﬁt of the model to observed",
      "page": 49
    },
    {
      "level": "H5",
      "text": "data; this measure underlies much of our work on learning models from data. The temporal",
      "page": 49
    },
    {
      "level": "H5",
      "text": "models we deﬁne provide a formal framework for deﬁning a general trend toward persistence of",
      "page": 49
    },
    {
      "level": "H5",
      "text": "state over time, in a way that does not raise inconsistencies when change does occur.",
      "page": 49
    },
    {
      "level": "H5",
      "text": "In general, part of the rich development in this ﬁeld is due to the close and continuous",
      "page": 49
    },
    {
      "level": "H5",
      "text": "interaction between theory and practice. In this ﬁeld, unlike many others, the distance between",
      "page": 49
    },
    {
      "level": "H5",
      "text": "theory and practice is quite small, and there is a constant ﬂow of ideas and problems between",
      "page": 49
    },
    {
      "level": "H5",
      "text": "them. Problems or ideas arise in practical applications and are analyzed and subsequently",
      "page": 49
    },
    {
      "level": "H5",
      "text": "developed in more theoretical papers. Algorithms for which no theoretical analysis exists are",
      "page": 49
    },
    {
      "level": "H5",
      "text": "tried out in practice, and the proﬁle of where they succeed and fail often provides the basis for",
      "page": 49
    },
    {
      "level": "H5",
      "text": "subsequent analysis. This rich synergy leads to a continuous and vibrant development, and it is",
      "page": 49
    },
    {
      "level": "H5",
      "text": "a key factor in the success of this area.",
      "page": 49
    },
    {
      "level": "H4",
      "text": "1.4 Historical Notes",
      "page": 49
    },
    {
      "level": "H5",
      "text": "The foundations of probability theory go back to the sixteenth century, when Gerolamo Cardano",
      "page": 49
    },
    {
      "level": "H5",
      "text": "began a formal analysis of games of chance, followed by additional key developments by Pierre",
      "page": 49
    },
    {
      "level": "H5",
      "text": "de Fermat and Blaise Pascal",
      "page": 49
    },
    {
      "level": "H5",
      "text": "in the seventeenth century. The initial development involved",
      "page": 49
    },
    {
      "level": "H5",
      "text": "only discrete probability spaces, and the analysis methods were purely combinatorial. The",
      "page": 49
    },
    {
      "level": "H5",
      "text": "foundations of modern probability theory, with its measure-theoretic underpinnings, were laid",
      "page": 49
    },
    {
      "level": "H5",
      "text": "by Andrey Kolmogorov in the 1930s.",
      "page": 49
    },
    {
      "level": "H5",
      "text": "expert systems",
      "page": 50
    },
    {
      "level": "H5",
      "text": "1.4. Historical Notes",
      "page": 50
    },
    {
      "level": "H5",
      "text": "Particularly central to the topics of this book is the so-called Bayes theorem, shown in the",
      "page": 50
    },
    {
      "level": "H5",
      "text": "eighteenth century by the Reverend Thomas Bayes (Bayes 1763). This theorem allows us to use",
      "page": 50
    },
    {
      "level": "H5",
      "text": "a model that tells us the conditional probability of event a given event b (say, a symptom given",
      "page": 50
    },
    {
      "level": "H5",
      "text": "a disease) in order to compute the contrapositive: the conditional probability of event b given",
      "page": 50
    },
    {
      "level": "H5",
      "text": "event a (the disease given the symptom). This type of reasoning is central to the use of graphical",
      "page": 50
    },
    {
      "level": "H5",
      "text": "models, and it explains the choice of the name Bayesian network.",
      "page": 50
    },
    {
      "level": "H5",
      "text": "The notion of representing the interactions between variables in a multidimensional distribu-",
      "page": 50
    },
    {
      "level": "H5",
      "text": "tion using a graph structure originates in several communities, with very different motivations.",
      "page": 50
    },
    {
      "level": "H5",
      "text": "In the area of statistical physics, this idea can be traced back to Gibbs (1902), who used an",
      "page": 50
    },
    {
      "level": "H5",
      "text": "undirected graph to represent the distribution over a system of interacting particles.",
      "page": 50
    },
    {
      "level": "H5",
      "text": "In the",
      "page": 50
    },
    {
      "level": "H5",
      "text": "area of genetics, this idea dates back to the work on path analysis of Sewal Wright (Wright",
      "page": 50
    },
    {
      "level": "H5",
      "text": "1921, 1934). Wright proposed the use of a directed graph to study inheritance in natural species.",
      "page": 50
    },
    {
      "level": "H5",
      "text": "This idea, although largely rejected by statisticians at the time, was subsequently adopted by",
      "page": 50
    },
    {
      "level": "H5",
      "text": "economists and social scientists (Wold 1954; Blalock, Jr. 1971). In the ﬁeld of statistics, the idea",
      "page": 50
    },
    {
      "level": "H5",
      "text": "of analyzing interactions between variables was ﬁrst proposed by Bartlett (1935), in the study",
      "page": 50
    },
    {
      "level": "H5",
      "text": "of contingency tables, also known as log-linear models. This idea became more accepted by the",
      "page": 50
    },
    {
      "level": "H5",
      "text": "statistics community in the 1960s and 70s (Vorobev 1962; Goodman 1970; Haberman 1974).",
      "page": 50
    },
    {
      "level": "H5",
      "text": "In the ﬁeld of computer science, probabilistic methods lie primarily in the realm of Artiﬁcial",
      "page": 50
    },
    {
      "level": "H5",
      "text": "Intelligence (AI). The AI community ﬁrst encountered these methods in the endeavor of building",
      "page": 50
    },
    {
      "level": "H5",
      "text": "expert systems, computerized systems designed to perform difficult tasks, such as oil-well location",
      "page": 50
    },
    {
      "level": "H5",
      "text": "or medical diagnosis, at an expert level. Researchers in this ﬁeld quickly realized the need for",
      "page": 50
    },
    {
      "level": "H5",
      "text": "methods that allow the integration of multiple pieces of evidence, and that provide support",
      "page": 50
    },
    {
      "level": "H5",
      "text": "for making decisions under uncertainty. Some early systems (de Bombal et al. 1972; Gorry and",
      "page": 50
    },
    {
      "level": "H5",
      "text": "Barnett 1968; Warner et al. 1961) used probabilistic methods, based on the very restricted naive",
      "page": 50
    },
    {
      "level": "H5",
      "text": "Bayes model. This model restricts itself to a small set of possible hypotheses (e.g., diseases) and",
      "page": 50
    },
    {
      "level": "H5",
      "text": "assumes that the different evidence variables (e.g., symptoms or test results) are independent",
      "page": 50
    },
    {
      "level": "H5",
      "text": "given each hypothesis. These systems were surprisingly successful, performing (within their area",
      "page": 50
    },
    {
      "level": "H5",
      "text": "of expertise) at a level comparable to or better than that of experts. For example, the system",
      "page": 50
    },
    {
      "level": "H5",
      "text": "of de Bombal et al. (1972) averaged over 90 percent correct diagnoses of acute abdominal pain,",
      "page": 50
    },
    {
      "level": "H5",
      "text": "whereas expert physicians were averaging around 65 percent.",
      "page": 50
    },
    {
      "level": "H5",
      "text": "Despite these successes, this approach fell into disfavor in the AI community, owing to a com-",
      "page": 50
    },
    {
      "level": "H5",
      "text": "bination of several factors. One was the belief, prevalent at the time, that artiﬁcial intelligence",
      "page": 50
    },
    {
      "level": "H5",
      "text": "should be based on similar methods to human intelligence, combined with a strong impression",
      "page": 50
    },
    {
      "level": "H5",
      "text": "that people do not manipulate numbers when reasoning. A second issue was the belief that the",
      "page": 50
    },
    {
      "level": "H5",
      "text": "strong independence assumptions made in the existing expert systems were fundamental to the",
      "page": 50
    },
    {
      "level": "H5",
      "text": "approach. Thus, the lack of a ﬂexible, scalable mechanism to represent interactions between",
      "page": 50
    },
    {
      "level": "H5",
      "text": "variables in a distribution was a key factor in the rejection of the probabilistic framework.",
      "page": 50
    },
    {
      "level": "H5",
      "text": "The rejection of probabilistic methods was accompanied by the invention of a range of",
      "page": 50
    },
    {
      "level": "H5",
      "text": "alternative formalisms for reasoning under uncertainty, and the construction of expert systems",
      "page": 50
    },
    {
      "level": "H5",
      "text": "based on these formalisms (notably Prospector by Duda, Gaschnig, and Hart 1979 and Mycin by",
      "page": 50
    },
    {
      "level": "H5",
      "text": "Buchanan and Shortliffe 1984). Most of these formalisms used the production rule framework,",
      "page": 50
    },
    {
      "level": "H5",
      "text": "where each rule is augmented with some number(s) deﬁning a measure of “conﬁdence” in",
      "page": 50
    },
    {
      "level": "H5",
      "text": "its validity. These frameworks largely lacked formal semantics, and many exhibited signiﬁcant",
      "page": 50
    },
    {
      "level": "H5",
      "text": "problems in key reasoning patterns. Other frameworks for handling uncertainty proposed at",
      "page": 50
    },
    {
      "level": "H5",
      "text": "the time included fuzzy logic, possibility theory, and Dempster-Shafer belief functions. For a",
      "page": 50
    }
  ]
}